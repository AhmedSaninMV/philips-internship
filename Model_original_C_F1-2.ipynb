{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_original_C_F1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "01eTIqHeOfXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2 \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import pandas as pd\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from tensorflow.keras.models import load_model\n",
        "from tqdm import tqdm\n",
        " \n",
        "#from tensorflow.keras.callbacks import TensorBoard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMObku-mUruh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9eebcc97-f4b6-44a6-936f-d57951c52e53"
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 37kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 48.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.31.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.3.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (49.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=d7e42833b2f73a6c20beb7470cfa0f0f1df368b1943044ac92e2c8706e9a72ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, keras-applications, tensorflow-estimator, gast, tensorflow\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG-DW7BLOkIr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "63323016-d051-495a-cee4-b944e4be5da7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6wEdHkkOmhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9167eabc-bcb7-4400-c315-2eca5f2d2365"
      },
      "source": [
        "from os import listdir\n",
        "\n",
        "#path_img = '/content/drive/My Drive/output/DA4/Image'\n",
        "#path_mark = '/content/drive/My Drive/output/DA4/Landmarks'\n",
        "\n",
        "#Test1\n",
        "#path_img = '/content/drive/My Drive/Database/sitk_aug/test_images'\n",
        "#path_mark = '/content/drive/My Drive/Database/sitk_aug/test_landmarks'\n",
        "\n",
        "#Test2\n",
        "#path_img = '/content/drive/My Drive/Database/sitk_aug/test_images1'\n",
        "#path_mark = '/content/drive/My Drive/Database/sitk_aug/test_landmarks1'\n",
        "\n",
        "\n",
        "#Test3\n",
        "#path_img = '/content/drive/My Drive/Dataset_new/test/Image'\n",
        "#path_mark = '/content/drive/My Drive/Dataset_new/test/Landmarks'\n",
        "\n",
        "#real\n",
        "path_img = '/content/drive/My Drive/Dataset/image'\n",
        "path_mark = '/content/drive/My Drive/Dataset/landmark'\n",
        "\n",
        "ImageFileNames=[]\n",
        "FileNames=listdir(path_img)\n",
        "for names in FileNames:\n",
        "    if names.endswith(\".nii\"):\n",
        "        ImageFileNames.append(names)\n",
        "        \n",
        "len(ImageFileNames)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-C6JBMOsv5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "4f1691ce-f634-449c-cb16-7102a988edd3"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import itertools\n",
        "import os\n",
        "\n",
        "\n",
        "def resize_data(data):\n",
        "    initial_size_x = data.shape[0]\n",
        "    initial_size_y = data.shape[1]\n",
        "    initial_size_z = data.shape[2]\n",
        "\n",
        "    new_size_x = 64\n",
        "    new_size_y = 64\n",
        "    new_size_z = 64\n",
        "\n",
        "    delta_x = initial_size_x / new_size_x\n",
        "    delta_y = initial_size_y / new_size_y\n",
        "    delta_z = initial_size_z / new_size_z\n",
        "\n",
        "    new_data = np.zeros((new_size_x, new_size_y, new_size_z))\n",
        "\n",
        "    for x, y, z in itertools.product(range(new_size_x),\n",
        "                                     range(new_size_y),\n",
        "                                     range(new_size_z)):\n",
        "        new_data[x][y][z] = data[int(x * delta_x)][int(y * delta_y)][int(z * delta_z)]\n",
        "\n",
        "    return new_data\n",
        "\n",
        "\n",
        "def PreProcess(InputImages):\n",
        "    \n",
        "    #output=np.zeros(InputImages.shape,dtype=np.float)\n",
        "    InputImages=InputImages.astype(np.float)\n",
        "    for i in range(InputImages.shape[0]):\n",
        "        try:\n",
        "            if np.max(InputImages[i,:,:,:,:])==0:\n",
        "                print(np.max(InputImages[i,:,:,:,:]))\n",
        "                #plt.imshow(InputImages[i,:,:,:,:])\n",
        "                \n",
        "            InputImages[i,:,:,:,:]=InputImages[i,:,:,:,:]/np.max(InputImages[i,:,:,:,:])\n",
        "#            output[i,:,:,:] = (output[i,:,:,:]* 2)-1\n",
        "        except:\n",
        "            InputImages[i,:,:,:]=InputImages[i,:,:,:]/np.max(InputImages[i,:,:,:])\n",
        "#            output[i,:,:] = (output[i,:,:]* 2) -1\n",
        "            \n",
        "    return InputImages\n",
        "\n",
        "Images=np.zeros((len(ImageFileNames),64, 64, 64, 1),dtype=np.uint8)    \n",
        "LandmarkLocations=np.zeros((len(ImageFileNames),3,21),dtype=np.uint8)\n",
        "#Images=np.zeros((150,64, 64, 64, 1),dtype=np.uint8)    \n",
        "#LandmarkLocations=np.zeros((150,3,21),dtype=np.uint8)\n",
        "\n",
        "\n",
        "#Images=np.zeros((1,64, 64, 64, 1),dtype=np.uint8)    \n",
        "#LandmarkLocations=np.zeros((1,3,21),dtype=np.uint8)\n",
        "## Loading all .nii files and landmark from .txt files\n",
        "from numpy import zeros, newaxis\n",
        "\n",
        "for i in tqdm(range(len(ImageFileNames))):\n",
        "    img = nib.load(path_img+'/'+ImageFileNames[i])\n",
        "    #downsampled_nii = resample_img(img, target_affine=np.eye(3)*256/63 , interpolation='nearest')\n",
        "    img = np.array(img.dataobj)\n",
        "    img = resize_data(img)\n",
        "    #img=(img/np.max(img))\n",
        "    img = img[:, :, :,newaxis]\n",
        "    #print (img.dtype)\n",
        "    Images[i,:,:,:,:]=img \n",
        "    #for j in range(20):\n",
        "      #Images[i+len(ImageFileNames)*j,:,:,:,:]=img \n",
        "    FileName=ImageFileNames[i]\n",
        "    FileName=FileName[:-4]\n",
        "    \n",
        "    df = pd.read_csv(path_mark+'/'+FileName+'.txt', header=None)\n",
        "    landmark_x = df.iloc[:,0].values\n",
        "    landmark_y = df.iloc[:,1].values\n",
        "    landmark_z = df.iloc[:,2].values\n",
        "    LandmarkLocations[i,0,:] = landmark_x//4\n",
        "    LandmarkLocations[i,1,:] = landmark_y//4\n",
        "    LandmarkLocations[i,2,:] = landmark_z//4\n",
        "    #for k in range(20):\n",
        "     # LandmarkLocations[i+len(ImageFileNames)*j,0,:] = landmark_x//4\n",
        "      #LandmarkLocations[i+len(ImageFileNames)*j,1,:] = landmark_y//4\n",
        "      #LandmarkLocations[i+len(ImageFileNames)*j,2,:] = landmark_z//4\n",
        "## ploating a random image \n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.imshow(Images[1,:,:,24,0])\n",
        "plt.colorbar()\n",
        "plt.plot()\n",
        "\n",
        "X_train = PreProcess(Images)\n",
        "X_train.shape\n",
        "\n",
        "Num_landmarks = 5   # given as 5 because of the memory contraints\n",
        "## creating the heatmaps for traing from the given landmarks\n",
        "Images_HeatMaps=np.zeros((X_train.shape[0],X_train.shape[1],X_train.shape[2],X_train.shape[3],Num_landmarks),dtype=np.float)\n",
        "\n",
        "Image_heatmap=np.zeros((64, 64, 64),dtype=np.float)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [02:19<00:00,  1.36s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVFe9mvfOvqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "136f57d7-43e1-4b77-b482-9d0f1c503c5b"
      },
      "source": [
        "\n",
        "for i in tqdm(range(X_train.shape[0])):\n",
        "    for k in range(Num_landmarks):\n",
        "      \n",
        "#        h=np.argwhere(Images_seg[i,:,:]==2*Ind_impo_landmarks_matlab[k])    \n",
        "        lms_1=LandmarkLocations[i,0,k]\n",
        "        lms_2=LandmarkLocations[i,1,k]\n",
        "        lms_3=LandmarkLocations[i,2,k]\n",
        "        #print(lms_1,lms_2,lms_3)\n",
        "        Image_heatmap[:,:,:]=0\n",
        "        Image_heatmap[lms_1,lms_2,lms_3]=1\n",
        "        Image_heatmap=gaussian_filter(Image_heatmap, sigma=2)\n",
        "        ## Here we can change the value multipied to the heatmap from 100 and see if we get better results\n",
        "        Image_heatmap=(Image_heatmap*100)\n",
        "        Images_HeatMaps[i,:,:,:,k]=Image_heatmap\n",
        "\n",
        "Y_train_heatmap = Images_HeatMaps\n",
        "\n",
        "Y_train_heatmap.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 103/103 [00:06<00:00, 16.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(103, 64, 64, 64, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2rJBulaQRWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa5d4096-7c9a-429d-f17f-93fa3b369c87"
      },
      "source": [
        "\n",
        "\n",
        "x_data = X_train#np.vstack([x_train,x_val])\n",
        "y_data = Y_train_heatmap#np.vstack([y_train,y_val])\n",
        "\n",
        "\n",
        "\n",
        "del X_train\n",
        "del Y_train_heatmap\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zj9xrfPl3wB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "4d105f40-2a71-4647-baa6-5f70d1eeb12c"
      },
      "source": [
        "x_test1 = X_train#np.vstack([x_train,x_val])\n",
        "y_test1 = Y_train_heatmap#"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-0719127f823d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;31m#np.vstack([x_train,x_val])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train_heatmap\u001b[0m\u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOYBjy2AOzjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## returns expected keypoints\n",
        "def spatial_softArgmax3d(filters, temperature = 1.0):\n",
        "    \n",
        "    shape = tf.shape(filters)\n",
        "    #print(\"Shape : {}\".format(shape))\n",
        "    length , height, width, num_channels = shape[1], shape[2], shape[3] ,shape[4]\n",
        "    \n",
        "    posx, posy, posz = tf.meshgrid(tf.range(length),tf.range(height), tf.range(width), indexing='ij')\n",
        "    #print(\"posx : {},posy : {},posz : {}\".format(posx,posy,posz))\n",
        "    \n",
        "    posx = tf.reshape(posx, [height * width * length])\n",
        "    posy = tf.reshape(posy, [height * width * length])\n",
        "    posz = tf.reshape(posz, [height * width * length])\n",
        "    posx = tf.cast(posx,tf.float32)\n",
        "    posy = tf.cast(posy,tf.float32)\n",
        "    posz = tf.cast(posz,tf.float32)\n",
        "\n",
        "    # The below transformation is very inmportant to get the expected results \n",
        "    filters = tf.reshape(tf.transpose(filters, [0, 4, 1, 2 ,3]), [num_channels, height * width * length])\n",
        "    \n",
        "    softmax_attention = tf.nn.softmax(filters/0.001)\n",
        "    #print(softmax_attention)\n",
        "    \n",
        "    expected_x = tf.reduce_sum(posx * softmax_attention, 1, keepdims = True)\n",
        "    expected_y = tf.reduce_sum(posy * softmax_attention, 1, keepdims = True)\n",
        "    expected_z = tf.reduce_sum(posz * softmax_attention, 1, keepdims = True)\n",
        "    \n",
        "    expected_xyz = tf.concat([expected_x, expected_y, expected_z], axis = 1)\n",
        "    \n",
        "    feature_keypoints = tf.reshape(expected_xyz, [-1, num_channels * 3])\n",
        "\n",
        "    return expected_xyz\n",
        "# this loss function gives a measure of how close is y_true heatmap is from y_pred heatmap \n",
        "# taking all the points in the gaussian and not just the keypoints\n",
        "# not a final version still some modification is requried\n",
        "def Maskedloss(y_true,y_pred):\n",
        "  y_true1 = tf.reshape(tf.transpose(y_true, [0, 4, 1, 2 ,3]), [5, 64 * 64 * 64])\n",
        "  y_pred1 = tf.reshape(tf.transpose(y_pred, [0, 4, 1, 2 ,3]), [5, 64 * 64 * 64])\n",
        "  A = K.abs(y_pred1-y_true1)\n",
        "  A = tf.math.multiply(y_true1,A)\n",
        "  A = tf.reduce_sum(A,1,keepdims = True)\n",
        "  return A\n",
        "## its not in a usable form need to do some transformation and reshaping on y_true and y_pred\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "  numerator = 2 * tf.reduce_sum(y_true * y_pred, axis=(1,2,3))\n",
        "  denominator = tf.reduce_sum(y_true + y_pred, axis=(1,2,3))\n",
        "\n",
        "  return 1 - numerator / denominator\n",
        "## its not in a usable form need to do some transformation and reshaping on y_true and y_pred\n",
        "#def tversky_loss(beta):\n",
        "def loss(y_true, y_pred, beta = 0.5):\n",
        "  numerator = tf.reduce_sum(y_true * y_pred, axis=-1)\n",
        "  denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)\n",
        "\n",
        "  return 1 - (numerator + 1) / (tf.reduce_sum(denominator, axis=-1) + 1)\n",
        "\n",
        "  return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSJgLikDO2Cj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "31a3b985-20d4-4bae-cdc9-80a91e80116a"
      },
      "source": [
        "%load_ext tensorboard\n",
        "from tensorflow.compat.v1.keras import backend as K\n",
        "from glob import glob\n",
        "\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import datetime\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import regularizers\n",
        "from scipy import io\n",
        "import argparse\n",
        "import tensorflow as tf\n",
        "from keras import initializers\n",
        "## defining the loss functions using the help of the functions defined above\n",
        "def custom_loss_reg_1 (y_true, y_pred):\n",
        "    #A = tensorflow.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "    #B = tensorflow.keras.losses.mean_absolute_error(y_true, y_pred)\n",
        "    \n",
        "    A = spatial_softArgmax3d(y_pred)\n",
        "    C = spatial_softArgmax3d(y_true)\n",
        "    D = K.mean(K.sqrt(K.sum(K.square(C - A), axis=1)))\n",
        "    #D = tensorflow.keras.losses.mean_absolute_error(C, A)\n",
        "    #D = tensorflow.keras.losses.mean_squared_error(C, A)\n",
        "    return(D)\n",
        "\n",
        "def custom_loss_reg_0 (y_true, y_pred):\n",
        "  #A = tensorflow.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "  B = tensorflow.keras.losses.mean_absolute_error(y_true, y_pred)\n",
        "  return (B)\n",
        "\n",
        "# not completed \n",
        "def custom_loss_reg_3 (y_true, y_pred, w = 0.2):\n",
        "    #A = tensorflow.keras.losses.mean_squared_error(y_true, y_pred)\n",
        "    #B = tensorflow.keras.losses.mean_absolute_error(y_true, y_pred)\n",
        "    \n",
        "    \n",
        "    A = Maskedloss(y_true, y_pred)\n",
        "    \n",
        "    return(A)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWWnuD5WO4_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!rm -rf ./logs/ \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrTAXxCjO6G2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "outputId": "fce7f468-e85c-43d9-9272-2c677d9869d2"
      },
      "source": [
        "\n",
        "NAME = \"model1\"\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "batch_size=1\n",
        "\n",
        "ngf=32\n",
        "kernelSize_1=(3,3,3)\n",
        "InputLayer=tensorflow.keras.layers.Input(shape=(64, 64, 64, 1))\n",
        "x_1=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_1, dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "x_1=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_1, dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_1)\n",
        "\n",
        "        \n",
        "kernelSize_2=(3,3,3)\n",
        "x_2=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_2, dilation_rate=(2, 2, 2),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "x_2=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_2,kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), dilation_rate=(2, 2, 2), activation='relu',padding='same',)(x_2)\n",
        "\n",
        "        \n",
        "        \n",
        "kernelSize_3=(3,3,3)\n",
        "x_3=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_3, dilation_rate=(3, 3, 3),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "x_3=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_3,kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), dilation_rate=(3, 3, 3), activation='relu',padding='same',)(x_3)\n",
        "\n",
        "        \n",
        "kernelSize_4=(3,3,3)\n",
        "x_4=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_4, dilation_rate=(4, 4, 4),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "x_4=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_4, dilation_rate=(4, 4, 4),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_4)\n",
        "\n",
        "        \n",
        "kernelSize_5=(3,3,3)\n",
        "x_5=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_5, dilation_rate=(5, 5, 5),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "x_5=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_5, dilation_rate=(5, 5, 5),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_5)\n",
        "\n",
        "\n",
        "\n",
        "#x_c = x_1        \n",
        "x_c=tensorflow.keras.layers.concatenate([x_1,x_2,x_3,x_4,x_5],axis=-1)\n",
        "x_c=tensorflow.keras.layers.Conv3D(8*ngf, kernel_size=(3,3,3), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)\n",
        "x_c=tensorflow.keras.layers.Conv3D(4*ngf, kernel_size=(2,2,2), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)\n",
        "x_c=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=(1,1,1), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)               \n",
        "FinalHeatMaps=tensorflow.keras.layers.Conv3D(Num_landmarks, kernel_size=(1,1,1), dilation_rate=(1, 1,1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='tanh',padding='same',)(x_c)\n",
        "\n",
        "        \n",
        "model_final=Model(inputs=InputLayer,outputs=FinalHeatMaps)\n",
        "model_final.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 64, 64, 64,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv3d (Conv3D)                 (None, 64, 64, 64, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_2 (Conv3D)               (None, 64, 64, 64, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_4 (Conv3D)               (None, 64, 64, 64, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_6 (Conv3D)               (None, 64, 64, 64, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_8 (Conv3D)               (None, 64, 64, 64, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_1 (Conv3D)               (None, 64, 64, 64, 6 55360       conv3d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_3 (Conv3D)               (None, 64, 64, 64, 6 55360       conv3d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_5 (Conv3D)               (None, 64, 64, 64, 6 55360       conv3d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_7 (Conv3D)               (None, 64, 64, 64, 6 55360       conv3d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_9 (Conv3D)               (None, 64, 64, 64, 6 55360       conv3d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 64, 3 0           conv3d_1[0][0]                   \n",
            "                                                                 conv3d_3[0][0]                   \n",
            "                                                                 conv3d_5[0][0]                   \n",
            "                                                                 conv3d_7[0][0]                   \n",
            "                                                                 conv3d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_10 (Conv3D)              (None, 64, 64, 64, 2 2212096     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_11 (Conv3D)              (None, 64, 64, 64, 1 262272      conv3d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_12 (Conv3D)              (None, 64, 64, 64, 6 8256        conv3d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv3d_13 (Conv3D)              (None, 64, 64, 64, 5 325         conv3d_12[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,764,229\n",
            "Trainable params: 2,764,229\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IUsGe1PLbT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(path):\n",
        "    \n",
        "  NAME = \"model1\"\n",
        "\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "  from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "  from tensorflow.keras.callbacks import EarlyStopping\n",
        "  batch_size=1\n",
        "\n",
        "  ngf=32\n",
        "  kernelSize_1=(3,3,3)\n",
        "  InputLayer=tensorflow.keras.layers.Input(shape=(64, 64, 64, 1))\n",
        "  x_1=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_1, dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "  x_1=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_1, dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_1)\n",
        "\n",
        "          \n",
        "  kernelSize_2=(3,3,3)\n",
        "  x_2=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_2, dilation_rate=(2, 2, 2),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "  x_2=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_2,kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), dilation_rate=(2, 2, 2), activation='relu',padding='same',)(x_2)\n",
        "\n",
        "          \n",
        "          \n",
        "  kernelSize_3=(3,3,3)\n",
        "  x_3=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_3, dilation_rate=(3, 3, 3),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "  x_3=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_3,kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), dilation_rate=(3, 3, 3), activation='relu',padding='same',)(x_3)\n",
        "\n",
        "          \n",
        "  kernelSize_4=(3,3,3)\n",
        "  x_4=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_4, dilation_rate=(4, 4, 4),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "  x_4=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_4, dilation_rate=(4, 4, 4),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_4)\n",
        "\n",
        "          \n",
        "  kernelSize_5=(3,3,3)\n",
        "  x_5=tensorflow.keras.layers.Conv3D(ngf, kernel_size=kernelSize_5, dilation_rate=(5, 5, 5),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(InputLayer)\n",
        "  x_5=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=kernelSize_5, dilation_rate=(5, 5, 5),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_5)\n",
        "\n",
        "\n",
        "\n",
        "  #x_c = x_1        \n",
        "  x_c=tensorflow.keras.layers.concatenate([x_1,x_2,x_3,x_4,x_5],axis=-1)\n",
        "  x_c=tensorflow.keras.layers.Conv3D(8*ngf, kernel_size=(3,3,3), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)\n",
        "  x_c=tensorflow.keras.layers.Conv3D(4*ngf, kernel_size=(2,2,2), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)\n",
        "  x_c=tensorflow.keras.layers.Conv3D(2*ngf, kernel_size=(1,1,1), dilation_rate=(1, 1, 1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='relu',padding='same',)(x_c)               \n",
        "  FinalHeatMaps=tensorflow.keras.layers.Conv3D(Num_landmarks, kernel_size=(1,1,1), dilation_rate=(1, 1,1),kernel_initializer='he_normal', bias_initializer=initializers.Constant(0.1), activation='tanh',padding='same',)(x_c)\n",
        "\n",
        "          \n",
        "  model_final=Model(inputs=InputLayer,outputs=FinalHeatMaps)\n",
        "  #model_final.summary()\n",
        "  UsedOptimizer = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
        "  #UsedOptimizer=tensorflow.keras.optimizers.RMSprop(lr=0.0001, rho=0.9, epsilon=None, decay=0.0)\n",
        "\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20,restore_best_weights=True)\n",
        "  #checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='loss', verbose=1,\n",
        "      #save_best_only=False, mode='auto', period=1)\n",
        "\n",
        "\n",
        "  def MAE(y_true, y_pred):\n",
        "      A = spatial_softArgmax3d(y_pred)*3.0\n",
        "      C = spatial_softArgmax3d(y_true)*3.0\n",
        "      return K.mean(K.abs(C-A))\n",
        "\n",
        "  def MEE(y_true, y_pred):\n",
        "      print(y_true.shape)\n",
        "      A = spatial_softArgmax3d(y_pred)*3.0\n",
        "      C = spatial_softArgmax3d(y_true)*3.0\n",
        "      #print(\"A : {}\".format((K.sqrt(K.sum(K.square(A - C), axis=1)))))\n",
        "      return K.sqrt(K.sum(K.square(A - C), axis=1))\n",
        "\n",
        "  def RMSE(y_true, y_pred):\n",
        "      A = spatial_softArgmax3d(y_pred)\n",
        "      C = spatial_softArgmax3d(y_true)\n",
        "      return K.sqrt(K.mean(K.square(A - C), axis=1))\n",
        "\n",
        "      \n",
        "  model_final.compile(loss=custom_loss_reg_1, optimizer=UsedOptimizer,metrics=[MAE,MEE])    \n",
        "\n",
        "\n",
        "  #checkpoint_path = \"/content/drive/My Drive/Database/Model_training_5/Original/cp.ckpt\"\n",
        "  #checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "  filepath=\"/content/drive/My Drive/Database/Model_training_5_new/DA1/epochs:{epoch:03d}-val_loss:{val_loss:.3f}.hdf5\"\n",
        "  checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_freq='epoch')\n",
        "\n",
        "  #cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "  #                                   save_weights_only=True,\n",
        "  #                                   verbose=1)\n",
        "  #filepath = '/content/drive/My Drive/Database/Model_training_5/DA1'\n",
        "  #checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='max',save_freq='epoch')\n",
        "  #callbacks_list = [checkpoint]\n",
        "  model_final.load_weights(path)\n",
        "  return model_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTi1lSsYO-Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import CSVLogger\n",
        "\n",
        "\n",
        "UsedOptimizer = optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20,restore_best_weights=True)\n",
        "\n",
        "csv_logger = CSVLogger(\"/content/drive/My Drive/Dataset/20/model_history_log.csv\", append=True)\n",
        "\n",
        "def MAE(y_true, y_pred):\n",
        "    A = spatial_softArgmax3d(y_pred)\n",
        "    C = spatial_softArgmax3d(y_true)\n",
        "    return K.mean(K.abs(C-A))*3.0\n",
        "\n",
        "def MEE(y_true, y_pred):\n",
        "    print(y_true.shape)\n",
        "    A = spatial_softArgmax3d(y_pred)\n",
        "    C = spatial_softArgmax3d(y_true)\n",
        "    return K.mean(K.sqrt(K.sum(K.square(A - C), axis=1)))*3.0\n",
        "\n",
        "def RMSE(y_true, y_pred):\n",
        "    A = spatial_softArgmax3d(y_pred)\n",
        "    C = spatial_softArgmax3d(y_true)\n",
        "    return K.mean(K.sqrt(K.mean(K.square(A - C), axis=1)))*3.0\n",
        "\n",
        "    \n",
        "model_final.compile(loss=custom_loss_reg_3, optimizer=UsedOptimizer,metrics=[MAE,MEE,RMSE])    \n",
        "\n",
        "\n",
        "filepath=\"/content/drive/My Drive/Dataset/20/epochs:{epoch:03d}-val_loss:{val_loss:.3f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min',save_freq='epoch')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62OTLWk7mS6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_final.load_weights('/content/drive/My Drive/Testing/Type2/epochs:124-val_loss:1.267.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7QqNaTyQc5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_test1 = np.load('/content/drive/My Drive/Database/stored_numpy/x_test1.npy')\n",
        "y_test1 = np.load('/content/drive/My Drive/Database/stored_numpy/y_test1.npy')\n",
        "\n",
        "x_test2 = np.load('/content/drive/My Drive/Database/stored_numpy/x_test2.npy')\n",
        "y_test2 = np.load('/content/drive/My Drive/Database/stored_numpy/y_test2.npy')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBKwxVGoZqTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/x_test1.npy\",x_test1)\n",
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/y_test1.npy\",y_test1)\n",
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/x_test2.npy\",x_test2)\n",
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/y_test2.npy\",y_test2)\n",
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/x_test3.npy\",x_test3)\n",
        "np.save(\"/content/drive/My Drive/Database/stored_numpy/y_test3.npy\",y_test3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH-H-dHSD7od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(3, True, 1)\n",
        "t = []\n",
        "v = []\n",
        "for train, val in kfold.split(x_data):\n",
        "  t.append(train)\n",
        "  v.append(val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTyxMnNyotLP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "a2f40868-b6da-4671-a439-353afe5612d6"
      },
      "source": [
        "x_train = x_data[0:70]\n",
        "y_train = y_data[0:70]\n",
        "x_val = x_data[70:103]\n",
        "y_val = y_data[70:103]\n",
        "\n",
        "History=model_final.fit(x_train, y_train,\n",
        "            batch_size=batch_size, shuffle=True, validation_data=(x_val,y_val),\n",
        "            epochs=500,#initial_epoch=34,\n",
        "            verbose=1,callbacks=[es,csv_logger,checkpoint])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            " 2/70 [..............................] - ETA: 28s - loss: 68.3973 - MAE: 31.2518 - MEE: 67.3209 - RMSE: 38.8677WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.8343s). Check your callbacks.\n",
            "70/70 [==============================] - ETA: 0s - loss: 43.5126 - MAE: 25.0232 - MEE: 50.0763 - RMSE: 28.9116(1, 64, 64, 64, 5)\n",
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0074s vs `on_test_batch_end` time: 0.2192s). Check your callbacks.\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 36.59632, saving model to /content/drive/My Drive/Dataset/20/epochs:001-val_loss:36.596.hdf5\n",
            "70/70 [==============================] - 67s 960ms/step - loss: 43.5126 - MAE: 25.0232 - MEE: 50.0763 - RMSE: 28.9116 - val_loss: 36.5963 - val_MAE: 26.9011 - val_MEE: 55.0099 - val_RMSE: 31.7600\n",
            "Epoch 2/500\n",
            "70/70 [==============================] - ETA: 0s - loss: 36.1349 - MAE: 27.9638 - MEE: 55.7145 - RMSE: 32.1668\n",
            "Epoch 00002: val_loss improved from 36.59632 to 35.13052, saving model to /content/drive/My Drive/Dataset/20/epochs:002-val_loss:35.131.hdf5\n",
            "70/70 [==============================] - 66s 945ms/step - loss: 36.1349 - MAE: 27.9638 - MEE: 55.7145 - RMSE: 32.1668 - val_loss: 35.1305 - val_MAE: 24.7939 - val_MEE: 49.4484 - val_RMSE: 28.5491\n",
            "Epoch 3/500\n",
            "70/70 [==============================] - ETA: 0s - loss: 22.8084 - MAE: 29.7819 - MEE: 59.4072 - RMSE: 34.2987\n",
            "Epoch 00003: val_loss improved from 35.13052 to 12.56833, saving model to /content/drive/My Drive/Dataset/20/epochs:003-val_loss:12.568.hdf5\n",
            "70/70 [==============================] - 66s 945ms/step - loss: 22.8084 - MAE: 29.7819 - MEE: 59.4072 - RMSE: 34.2987 - val_loss: 12.5683 - val_MAE: 37.1693 - val_MEE: 73.0154 - val_RMSE: 42.1555\n",
            "Epoch 4/500\n",
            "51/70 [====================>.........] - ETA: 15s - loss: 11.1278 - MAE: 27.6227 - MEE: 55.1667 - RMSE: 31.8505"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5UikYsYPBEB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e8de956-5923-420a-cde9-5e43f66c2e73"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "kfold = KFold(5, True, 1)\n",
        "t = []\n",
        "v = []\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  t.append(train)\n",
        "  v.append(train)\n",
        "\n",
        "i = 0\n",
        "x_train = x_data[t[i]]\n",
        "y_train = y_data[t[i]]\n",
        "x_val = x_data[v[i]]\n",
        "y_val = y_data[v[i]]\n",
        "\n",
        "History=model_final.fit(x_train, y_train,\n",
        "            batch_size=batch_size, shuffle=True, validation_data=(x_val,y_val),\n",
        "            epochs=500,\n",
        "            verbose=1,callbacks=[tensorboard_callback,es,checkpoint])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 164 samples, validate on 164 samples\n",
            "Epoch 1/500\n",
            "105/164 [==================>...........] - ETA: 55s - loss: 6.4878 - MAE: 5.6448 - MEE: 11.4137"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdyOKN4pxFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "\n",
        "hist_df = pd.DataFrame(History.history) \n",
        "hist_csv_file = '/content/drive/My Drive/Database/Model_training_5/DA1/history4.csv'\n",
        "with open(hist_csv_file, mode='w') as f:\n",
        "    hist_df.to_csv(f)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGAT0xQLRg16",
        "colab_type": "text"
      },
      "source": [
        "# **Test For One Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRr4LoV7RZ8Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2b48f210-859a-4211-ef92-d34bc4720b68"
      },
      "source": [
        "print(model_final.evaluate(x_test1, y_test1, batch_size=1))\n",
        "print(model_final.evaluate(x_test2, y_test2, batch_size=1))\n",
        "#print(model_final.evaluate(x_test3, y_test3, batch_size=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 7s 221ms/step - loss: 183853360.0000 - MAE: 1.4823 - MEE: 3.4725\n",
            "[183853360.0, 1.482269048690796, 3.4725425243377686]\n",
            "31/31 [==============================] - 7s 221ms/step - loss: 183852560.0000 - MAE: 1.3019 - MEE: 3.0135\n",
            "[183852560.0, 1.3018829822540283, 3.0134811401367188]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PWBd8K3mM8M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "3086d2a9-c0ef-4d1b-bb3a-45af46cfb200"
      },
      "source": [
        "print(model_final.evaluate(x_test1, y_test1, batch_size=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 8.2793 - MAE: 1.4823 - MEE: 3.4725\n",
            "[8.279302597045898, 1.482269048690796, 3.4725425243377686]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_CvRPreDf4i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "97559183-aad5-4f06-806b-cad9ee79367c"
      },
      "source": [
        "x_test = np.vstack([x_test1,x_test2])\n",
        "y_test = np.vstack([y_test1,y_test2])\n",
        "print(model_final.evaluate(x_test, y_test, batch_size=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 14s 224ms/step - loss: 183852960.0000 - MAE: 1.3935 - MEE: 3.2467\n",
            "[183852960.0, 1.393507480621338, 3.246654987335205]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbNU4vp2RloB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "f7c0c514-defe-4b87-d52c-d65f552c43f8"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(3, True, 1)\n",
        "t1 = []\n",
        "t2 = []\n",
        "for train, val in kfold.split(x_data):\n",
        "  x_train = x_data[train]\n",
        "  y_train = y_data[train]\n",
        "  x_val = x_data[val]\n",
        "  y_val = y_data[val]\n",
        "  t1.append(model_final.evaluate(x_train, y_train, batch_size=1))\n",
        "  t2.append(model_final.evaluate(x_val, y_val, batch_size=1))\n",
        "  \n",
        "print(np.mean(t1,axis=0))\n",
        "print(np.mean(t2,axis=0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68/68 [==============================] - 15s 225ms/step - loss: 1.2669 - MAE: 0.0000e+00 - MEE: 0.0000e+00\n",
            "35/35 [==============================] - 8s 221ms/step - loss: 7.3435 - MAE: 1.2916 - MEE: 3.0402\n",
            "69/69 [==============================] - 15s 225ms/step - loss: 4.3411 - MAE: 0.6552 - MEE: 1.5421\n",
            "34/34 [==============================] - 8s 221ms/step - loss: 1.2835 - MAE: 0.0000e+00 - MEE: 0.0000e+00\n",
            "69/69 [==============================] - 15s 225ms/step - loss: 4.3574 - MAE: 0.6552 - MEE: 1.5421\n",
            "34/34 [==============================] - 8s 221ms/step - loss: 1.2504 - MAE: 0.0000e+00 - MEE: 0.0000e+00\n",
            "[3.32180854 0.43678574 1.028078  ]\n",
            "[3.29245309 0.43054597 1.01339118]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmZ31a1RoELV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "196e6eda-25bb-43c6-c811-c0a70cd1e64b"
      },
      "source": [
        "for i in range(103):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)\n",
        "  print(np.abs(dd-d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_2:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "[[ 1.4612141 32.999992  26.7481   ]\n",
            " [ 5.528187   1.1607513 11.084013 ]\n",
            " [ 5.9114666 34.984673  11.013805 ]\n",
            " [ 5.000002  17.         5.       ]\n",
            " [ 4.0530815 19.53984   25.998386 ]]\n",
            "[[ 6.1963577 34.        20.31709  ]\n",
            " [ 5.537409  24.313175   8.627855 ]\n",
            " [17.95472   19.8316    15.279732 ]\n",
            " [ 9.789936  16.155994   0.5016289]\n",
            " [ 1.3452454 11.943012   7.7771416]]\n",
            "[[ 1.0856419 29.999985  31.615215 ]\n",
            " [19.        18.         1.       ]\n",
            " [12.999989  31.99998    7.994467 ]\n",
            " [ 5.        18.         8.       ]\n",
            " [ 2.3909988 19.560184  25.000027 ]]\n",
            "[[11.9856415  32.         10.000774  ]\n",
            " [10.210382   24.141342    2.9988956 ]\n",
            " [ 7.92791    22.646618   31.841152  ]\n",
            " [ 4.57642    16.919998    6.7194443 ]\n",
            " [ 0.88809013 30.053688   26.000015  ]]\n",
            "[[ 7.4889374 33.000008   4.006008 ]\n",
            " [17.997738  26.994831   7.731332 ]\n",
            " [12.994339  36.9998     6.999901 ]\n",
            " [ 7.978533  18.002838   4.9984207]\n",
            " [ 1.0352936 18.004547  26.       ]]\n",
            "[[ 0.8246937  32.000004   33.55707   ]\n",
            " [ 0.12731934  2.8196526  14.462566  ]\n",
            " [ 8.235195   18.1572     22.816692  ]\n",
            " [ 6.000252   16.998947    2.999199  ]\n",
            " [ 1.0162735   2.2097855  27.99952   ]]\n",
            "[[ 7.8595905 31.999996  16.615559 ]\n",
            " [ 7.0548954  9.682369  12.978739 ]\n",
            " [12.998383  33.99982    8.000065 ]\n",
            " [ 7.311428   4.0982437 17.051073 ]\n",
            " [ 1.0192642 18.349983  25.999905 ]]\n",
            "[[ 0.03566551 33.999996   23.116638  ]\n",
            " [ 3.8780098   0.47364426 10.61589   ]\n",
            " [14.760826   18.204433   22.23883   ]\n",
            " [ 0.06136322 12.4817505   6.9161034 ]\n",
            " [ 2.6555004   0.86086655 25.997253  ]]\n",
            "[[ 9.29491    38.999992   12.611477  ]\n",
            " [ 5.574753   31.090439    7.8114567 ]\n",
            " [ 5.7455406  24.952076   19.389435  ]\n",
            " [ 5.0000935  17.999607    3.0004272 ]\n",
            " [ 0.92806053  2.0594902  26.946014  ]]\n",
            "[[ 4.16634   34.99999   15.472939 ]\n",
            " [13.973572  28.892075  10.869311 ]\n",
            " [ 4.        37.        14.       ]\n",
            " [16.999813  23.000648   8.000965 ]\n",
            " [ 1.0831375  1.5981255 26.999962 ]]\n",
            "[[ 0.18954277 32.         21.947487  ]\n",
            " [ 8.711596   18.023357   11.015234  ]\n",
            " [16.98143    24.987732   20.02819   ]\n",
            " [13.761499   22.9421     13.720295  ]\n",
            " [ 4.8717384  28.741245   26.000015  ]]\n",
            "[[ 6.7696     35.999947   20.814941  ]\n",
            " [13.030968    0.9355564  10.9553385 ]\n",
            " [15.022457   16.301937   19.944988  ]\n",
            " [ 4.9488716  15.999218    3.003868  ]\n",
            " [ 0.72759056  6.3658485  28.972153  ]]\n",
            "[[ 0.04555511 34.999996   20.79794   ]\n",
            " [ 8.953453    7.511944    7.1717167 ]\n",
            " [12.795734   17.242542   18.296146  ]\n",
            " [ 7.1718903  17.519192    1.7888412 ]\n",
            " [ 0.678318    0.18037415 26.997467  ]]\n",
            "[[ 6.445921   33.99998    21.92923   ]\n",
            " [ 1.1658783  20.327644   11.355173  ]\n",
            " [12.417801   18.751087   22.814789  ]\n",
            " [ 8.751617   17.922703    0.06991959]\n",
            " [ 0.14529419  1.5548744  24.974228  ]]\n",
            "[[ 3.9752693  31.999996   21.713665  ]\n",
            " [ 6.0020638   1.9996986  14.998314  ]\n",
            " [16.952461   19.046963   22.095032  ]\n",
            " [14.875729   23.913498    0.91755676]\n",
            " [ 4.358982   17.874912   27.000053  ]]\n",
            "[[ 8.281996  33.999992  23.81612  ]\n",
            " [18.99502    2.89353    3.9986362]\n",
            " [ 8.121759  35.806515   6.5576   ]\n",
            " [10.039772   9.4283905  2.7472076]\n",
            " [ 2.3788223  6.090149  24.934807 ]]\n",
            "[[ 7.794073   31.         23.02655   ]\n",
            " [ 4.384472   21.64436     0.34731865]\n",
            " [ 0.57209396 20.391033   22.496925  ]\n",
            " [15.951614    3.0347824   4.9868355 ]\n",
            " [ 0.9015541   0.5714798  24.996231  ]]\n",
            "[[ 7.6220818 31.999985  24.040611 ]\n",
            " [ 3.3856964 15.642429   6.6460495]\n",
            " [12.114567  18.890125  22.856789 ]\n",
            " [ 1.122158  18.676826   2.       ]\n",
            " [ 0.8576851  1.3973312 26.999615 ]]\n",
            "[[15.997295  32.000004  20.878613 ]\n",
            " [ 4.0454597  2.639124  14.187977 ]\n",
            " [ 6.0937843 20.03255    4.2220154]\n",
            " [ 2.6955605  0.2159996 11.704226 ]\n",
            " [ 1.7117195 16.317207  26.99947  ]]\n",
            "[[ 0.57279587 37.999973   16.573105  ]\n",
            " [ 7.1836357  25.519875   11.545732  ]\n",
            " [15.122215   18.754208   22.739002  ]\n",
            " [ 4.978657   16.99599     5.9849052 ]\n",
            " [ 2.7006378  19.300694   24.999046  ]]\n",
            "[[ 0.8594303  34.000008   22.333935  ]\n",
            " [13.43935     0.73532486  2.1620579 ]\n",
            " [10.56805    24.356552   20.495884  ]\n",
            " [14.867043    1.1914959   2.9493103 ]\n",
            " [ 0.6141968   7.033394   26.934784  ]]\n",
            "[[11.06971   34.        16.743385 ]\n",
            " [13.999998   2.0580387  8.999955 ]\n",
            " [12.992527  36.96718    9.015724 ]\n",
            " [18.999973  20.992851   8.992966 ]\n",
            " [ 2.0951977 20.31535   25.000011 ]]\n",
            "[[2.1353531e+00 3.5999996e+01 1.3561638e+01]\n",
            " [1.3738564e+01 2.9346813e+01 1.2781026e+01]\n",
            " [1.6760309e+01 2.2494839e+01 1.8123405e+01]\n",
            " [1.4005207e+01 2.2647858e-02 2.0031891e+00]\n",
            " [8.1035614e-02 2.2140942e+00 2.6999889e+01]]\n",
            "[[ 0.64312553 35.999996   28.233887  ]\n",
            " [14.99987    19.998512    2.0000362 ]\n",
            " [ 9.535152   28.307121   20.226582  ]\n",
            " [ 7.9903374  17.000557    4.99868   ]\n",
            " [ 1.3252716   3.7877846  26.99976   ]]\n",
            "[[ 2.4837189  35.         18.675995  ]\n",
            " [13.996254    0.9961834   9.999968  ]\n",
            " [10.180969   36.733772    1.212244  ]\n",
            " [ 4.115143   10.314987    1.3333588 ]\n",
            " [ 0.07341766 18.859566   24.999264  ]]\n",
            "[[ 1.9200783 33.000004  20.789795 ]\n",
            " [ 4.6007347  5.600128   3.2680168]\n",
            " [ 8.163511  21.306458  21.351852 ]\n",
            " [ 4.228203  17.229584   4.767765 ]\n",
            " [ 0.6096401  1.2465096 27.998466 ]]\n",
            "[[ 4.408161  37.000004  23.329414 ]\n",
            " [ 1.9177399  2.503353  11.071988 ]\n",
            " [ 4.1329155 38.84935   19.995968 ]\n",
            " [ 1.3563995 32.783833  28.472866 ]\n",
            " [ 0.4166584  4.2342033 27.000114 ]]\n",
            "[[10.287453   32.999992   24.895351  ]\n",
            " [11.008102    0.873436    9.388954  ]\n",
            " [ 0.13041878 27.787102   16.37864   ]\n",
            " [ 5.9838696  15.868027    8.976334  ]\n",
            " [ 0.7027168  28.342453   26.999928  ]]\n",
            "[[ 6.617281   33.999996   22.229767  ]\n",
            " [14.9990425   0.72431564  8.000643  ]\n",
            " [ 9.797218   29.07869    21.907452  ]\n",
            " [12.001934    2.9475975   0.07551193]\n",
            " [ 2.4610367  12.634056   26.996658  ]]\n",
            "[[ 0.29655457 37.999992   14.650127  ]\n",
            " [ 8.         32.          6.        ]\n",
            " [ 3.3433952  36.101902   10.821091  ]\n",
            " [19.608887   19.693928   12.384586  ]\n",
            " [11.107758   36.86842    14.997059  ]]\n",
            "[[9.9627857e+00 3.2000000e+01 7.0740356e+00]\n",
            " [1.8999996e+01 4.9996414e+00 7.7724457e-03]\n",
            " [7.6835670e+00 2.9622303e+01 1.4089680e+01]\n",
            " [9.7845535e+00 9.5236969e-01 6.0318069e+00]\n",
            " [1.4032364e+00 1.0596161e+01 2.5925148e+01]]\n",
            "[[ 8.992357  32.999992  27.998528 ]\n",
            " [18.99759   17.37733    1.0047417]\n",
            " [10.2673645 35.000004  16.221958 ]\n",
            " [ 3.0000286 24.999939  14.999954 ]\n",
            " [ 1.9835739 32.981525  25.999985 ]]\n",
            "[[5.8045349e+00 3.3999996e+01 2.2407925e+01]\n",
            " [1.1545437e+01 2.9198090e+01 7.7360821e+00]\n",
            " [6.3675766e+00 2.9090958e+01 1.3558350e+01]\n",
            " [7.9986115e+00 1.9951626e+01 3.9111137e+00]\n",
            " [1.7009735e-02 2.1217365e+01 2.4999622e+01]]\n",
            "[[7.9999523e+00 3.5000004e+01 5.0000896e+00]\n",
            " [6.4843807e+00 1.8810272e-02 1.2787916e+01]\n",
            " [1.1982597e+01 1.8035198e+01 2.0984558e+01]\n",
            " [9.1772175e+00 1.5287609e+01 4.5614624e-01]\n",
            " [6.0485840e-02 1.3291245e+00 2.6997551e+01]]\n",
            "[[ 1.8183594 33.99999   25.260307 ]\n",
            " [ 1.5747147 28.980793  20.983273 ]\n",
            " [18.160126  23.701988  14.280334 ]\n",
            " [14.976643   1.0013542  0.9802246]\n",
            " [ 2.1156845 14.176613  27.000042 ]]\n",
            "[[5.6417427e+00 3.2999996e+01 2.8303604e+01]\n",
            " [1.2975655e+01 2.3424149e-02 9.9963551e+00]\n",
            " [5.9570198e+00 3.4907440e+01 2.2776440e+01]\n",
            " [5.2308273e+00 8.1837769e+00 2.5094414e+00]\n",
            " [2.4551563e+00 2.5465591e+01 2.8000069e+01]]\n",
            "[[ 9.616594   29.999985    4.8707256 ]\n",
            " [ 8.308437   13.601952    2.373066  ]\n",
            " [ 0.13111877 32.816395    7.377386  ]\n",
            " [ 8.256159   14.8070755  10.142563  ]\n",
            " [ 8.674408   17.000534   25.999996  ]]\n",
            "[[ 3.3695183 30.000038   6.9227943]\n",
            " [21.000008   0.         2.999998 ]\n",
            " [ 8.73423   17.118889  20.403694 ]\n",
            " [ 3.5350037 15.882603   5.510666 ]\n",
            " [ 1.6527901 29.475842  30.999523 ]]\n",
            "[[ 6.569149   35.000008   14.831692  ]\n",
            " [16.728325   28.635956    2.0457516 ]\n",
            " [16.543148   20.50668    18.52964   ]\n",
            " [ 6.852333    0.49760246  3.7885437 ]\n",
            " [ 0.5723858   3.3749352  26.865463  ]]\n",
            "[[10.995548  38.999996   4.001215 ]\n",
            " [15.818531   2.0236626  3.3215065]\n",
            " [13.577358  15.309982  23.856499 ]\n",
            " [11.999996  14.964874   3.       ]\n",
            " [10.700687  34.53222   20.039837 ]]\n",
            "[[ 3.6521034  37.99996    19.234333  ]\n",
            " [10.946857    0.6725712  11.162376  ]\n",
            " [15.98386    19.0043     23.002144  ]\n",
            " [ 7.859009   14.094994    0.42345047]\n",
            " [ 7.179432    0.5169735  10.038265  ]]\n",
            "[[ 8.816124  33.999992  13.045109 ]\n",
            " [ 2.49613   24.80508    8.87026  ]\n",
            " [ 6.828396  23.283058  16.275803 ]\n",
            " [ 6.513794   6.082878   4.3923416]\n",
            " [ 0.9910412  4.9858513 25.999954 ]]\n",
            "[[10.881763  39.000015   7.170521 ]\n",
            " [13.59277    1.107048  10.981084 ]\n",
            " [13.906998  17.316452  20.233269 ]\n",
            " [ 5.0209427 17.96276    5.932846 ]\n",
            " [ 4.9810524 18.004066  25.99952  ]]\n",
            "[[ 5.3281784  33.999992   26.482586  ]\n",
            " [ 1.9993935  24.989311   13.996405  ]\n",
            " [14.699783   29.557373   11.961582  ]\n",
            " [ 7.5740204  17.578148    3.0133286 ]\n",
            " [ 0.03773689 20.007298   27.000023  ]]\n",
            "[[ 4.702917   33.999992   16.10582   ]\n",
            " [11.993927   27.99931     6.0007324 ]\n",
            " [11.14138    36.56314    13.25668   ]\n",
            " [15.947102    0.07113647  4.9485016 ]\n",
            " [ 2.4388695   0.8577843  22.252594  ]]\n",
            "[[ 3.369423   33.000004   13.671499  ]\n",
            " [ 8.86318     0.7188282  17.507353  ]\n",
            " [ 7.4651585  16.038612   31.991444  ]\n",
            " [ 0.06396866 17.495834    4.86755   ]\n",
            " [ 4.0419407  27.689949   27.999428  ]]\n",
            "[[ 5.904606   34.99999    19.135254  ]\n",
            " [14.598427    0.7735901   6.8068104 ]\n",
            " [13.970158   22.191422   19.027493  ]\n",
            " [15.979282    0.9747944   5.9506493 ]\n",
            " [ 0.03592682  5.3367157  26.959862  ]]\n",
            "[[13.899548   34.999992   15.761436  ]\n",
            " [16.09001     0.10022545  3.2081814 ]\n",
            " [15.6965065  18.943512   20.966007  ]\n",
            " [12.961611    1.1130066   0.98490906]\n",
            " [ 9.834835   31.479965    0.4188614 ]]\n",
            "[[ 1.8167686 39.999996   6.0568447]\n",
            " [ 6.914522  31.279675   3.8440742]\n",
            " [15.1596985 24.254623  22.475128 ]\n",
            " [ 5.9108543 19.151459   7.6525497]\n",
            " [ 7.758238  36.99864   27.991909 ]]\n",
            "[[10.412823  38.         6.8051624]\n",
            " [ 4.8045635  1.4406986 11.96811  ]\n",
            " [ 8.482628  34.547424   6.6998253]\n",
            " [ 6.2962685  8.548622  15.666309 ]\n",
            " [ 3.9624653 24.841194  27.000057 ]]\n",
            "[[ 1.59095   32.         8.710487 ]\n",
            " [ 8.085499  11.528378   5.1634846]\n",
            " [ 7.9993668 22.999992  29.999798 ]\n",
            " [ 0.5262947 25.968521  10.15727  ]\n",
            " [ 0.9012146 17.99879   26.000042 ]]\n",
            "[[ 9.781887  33.999992  26.680965 ]\n",
            " [ 3.7693844 25.74472    8.655304 ]\n",
            " [ 7.8255463 28.484245  11.306511 ]\n",
            " [ 6.9993896 18.998253   4.998661 ]\n",
            " [ 0.6938324 20.060215  26.00002  ]]\n",
            "[[ 7.1169186 33.999992  26.441414 ]\n",
            " [ 0.607317   4.658703  20.586395 ]\n",
            " [13.155708  18.75309   21.54863  ]\n",
            " [ 5.999996  23.971355   2.0001984]\n",
            " [ 0.5445976 17.496628  25.999817 ]]\n",
            "[[12.437065   34.000004    3.7338676 ]\n",
            " [ 2.697792    1.0830116  10.120725  ]\n",
            " [ 5.6761856  30.114735   14.591843  ]\n",
            " [ 6.432251    1.2551556  16.724718  ]\n",
            " [ 0.46407318 20.114086   24.00018   ]]\n",
            "[[10.447086   38.         20.754635  ]\n",
            " [17.61335     0.83953094  5.838722  ]\n",
            " [16.99997    15.999992   22.00002   ]\n",
            " [13.979752    1.0018902   1.0143967 ]\n",
            " [ 2.2082748   8.578358   24.465504  ]]\n",
            "[[ 7.3219757 33.999996   6.9443245]\n",
            " [18.        28.000004   8.999995 ]\n",
            " [15.999992  23.000256  16.999985 ]\n",
            " [ 3.7932205  9.137337   2.6032066]\n",
            " [ 0.7070446 20.862953  27.000183 ]]\n",
            "[[ 6.0730305 32.        12.310661 ]\n",
            " [10.4899025 21.515965  10.077962 ]\n",
            " [17.792458  22.812561  24.990017 ]\n",
            " [ 5.9912605 17.665134   5.982456 ]\n",
            " [ 3.2657585 22.844807  25.000435 ]]\n",
            "[[15.874878   35.999992   20.830475  ]\n",
            " [ 9.039366    0.7699566   2.25774   ]\n",
            " [ 4.180542   35.918774   15.568954  ]\n",
            " [10.987576    6.995844   15.998135  ]\n",
            " [ 0.56306076  8.151249   27.359432  ]]\n",
            "[[15.497879  33.        23.019405 ]\n",
            " [18.974144   9.92186    3.0528316]\n",
            " [14.804436  18.771793  24.14972  ]\n",
            " [ 6.4756203 11.010223   6.6387825]\n",
            " [ 2.8301086 15.8038025 28.000542 ]]\n",
            "[[12.565136  35.000004  18.194344 ]\n",
            " [12.227619   1.379034   7.8636303]\n",
            " [17.992157  19.650734  18.957035 ]\n",
            " [11.050045   2.0854912  1.4879303]\n",
            " [ 3.979845   3.0007172 24.00002  ]]\n",
            "[[5.5150318e+00 3.2000046e+01 1.7963821e+01]\n",
            " [1.9036985e+01 3.9915657e+00 7.9464178e+00]\n",
            " [1.6138504e+01 1.7048901e+01 2.1155018e+01]\n",
            " [1.5994556e+01 1.8996826e+01 2.7389526e-03]\n",
            " [2.6003532e+00 1.9964890e+01 2.9000130e+01]]\n",
            "[[ 7.2501106 34.000004  20.68195  ]\n",
            " [ 3.6280155 26.984676   7.6898613]\n",
            " [ 1.4265213 26.581676   9.771339 ]\n",
            " [18.943699   0.9284706 11.967947 ]\n",
            " [ 1.1422749  3.2400856 26.987839 ]]\n",
            "[[ 9.698515  38.99999    8.629105 ]\n",
            " [15.886387   2.02816    5.5177155]\n",
            " [13.744318  15.218021  22.610538 ]\n",
            " [ 6.921627  16.995522   5.952816 ]\n",
            " [ 2.8933182 21.8363    23.42382  ]]\n",
            "[[11.354565   33.999996   20.92437   ]\n",
            " [10.509932   28.983616    4.2132015 ]\n",
            " [ 1.4143867  30.848381   19.50393   ]\n",
            " [ 9.981695   29.971508    0.978199  ]\n",
            " [ 0.86196136  4.902199   27.000134  ]]\n",
            "[[ 4.4861355  33.999992   24.783772  ]\n",
            " [11.733601   27.923973   10.948735  ]\n",
            " [ 6.777981   23.900127   18.946281  ]\n",
            " [12.813852    0.41838455  2.0394974 ]\n",
            " [ 0.7198639   3.0109901  26.998947  ]]\n",
            "[[ 5.2176533 33.99999   17.698437 ]\n",
            " [ 8.008873  26.975521   7.9972534]\n",
            " [10.93383   19.094353  19.967018 ]\n",
            " [16.94508    1.9350166 11.993883 ]\n",
            " [ 1.2117004  4.3018475 26.999866 ]]\n",
            "[[12.789633  35.000004   4.664385 ]\n",
            " [17.007359   1.9993038  5.001274 ]\n",
            " [21.97689   35.975636   4.060625 ]\n",
            " [ 4.079014  18.641098   1.5789833]\n",
            " [ 3.4187965  4.508219  20.499626 ]]\n",
            "[[ 9.02705    36.000004   29.817001  ]\n",
            " [12.049936   22.65104     4.744198  ]\n",
            " [15.857986   21.210361   24.044285  ]\n",
            " [ 6.344944    8.053864    0.79418945]\n",
            " [ 4.933918   29.820732   27.000088  ]]\n",
            "[[ 7.804039  34.000008  22.079086 ]\n",
            " [ 8.250439   8.70084    5.059576 ]\n",
            " [ 6.931513  33.434902   6.953554 ]\n",
            " [ 0.999773   1.000061   7.999851 ]\n",
            " [ 1.451931   2.8677063 25.99961  ]]\n",
            "[[ 8.017342  35.999985  14.225334 ]\n",
            " [ 0.5000038 19.444595   1.1238403]\n",
            " [16.999039  18.360458  27.334984 ]\n",
            " [14.044364  17.23946    1.9008255]\n",
            " [ 2.682705  18.656387  26.995388 ]]\n",
            "[[ 1.703783   35.          7.124895  ]\n",
            " [18.993198   24.971764    3.9753437 ]\n",
            " [20.321281   18.96453    18.543755  ]\n",
            " [ 0.57814026  9.702887   15.209188  ]\n",
            " [ 0.44160652 14.309502   25.        ]]\n",
            "[[ 6.784971   35.         21.465118  ]\n",
            " [12.775486    0.96722984  8.9942665 ]\n",
            " [ 8.022743   35.949303   23.999725  ]\n",
            " [ 8.4449005   4.2054596   3.268322  ]\n",
            " [ 0.9259472   0.6916733  26.00005   ]]\n",
            "[[ 9.697254   33.999992   25.859695  ]\n",
            " [18.576763    0.66321945  6.335253  ]\n",
            " [17.530952   22.98462    20.714962  ]\n",
            " [19.41751    22.92453     4.4911957 ]\n",
            " [ 1.0247955  17.409668   27.000122  ]]\n",
            "[[ 4.264576  37.000046  23.014774 ]\n",
            " [ 7.916889   0.5555935 13.719637 ]\n",
            " [ 2.9089031 17.630302  24.934776 ]\n",
            " [ 4.923336  18.744987   2.0312157]\n",
            " [ 2.664484   3.3675976 13.304966 ]]\n",
            "[[ 4.974228   34.999992   20.460346  ]\n",
            " [ 8.500238   15.89452     5.2958336 ]\n",
            " [13.01569    16.023315   25.984146  ]\n",
            " [ 2.5895576  14.734711    2.9765778 ]\n",
            " [ 0.17854881  1.0290756  24.987873  ]]\n",
            "[[ 0.2950039  33.999996    6.2788296 ]\n",
            " [18.542282    1.4338722   2.4705334 ]\n",
            " [16.975128   22.986977   18.330154  ]\n",
            " [ 9.992939    1.8250332   4.8046074 ]\n",
            " [ 0.03428078 19.76812    26.999924  ]]\n",
            "[[ 5.128414   31.999985   14.189655  ]\n",
            " [ 4.061226    0.99817276  6.5423756 ]\n",
            " [13.979912   14.999924   24.998386  ]\n",
            " [ 1.083786   21.131702    2.6861992 ]\n",
            " [ 0.04570389 16.167862   25.000034  ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-014397646aee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m103\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpred_example_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_example_heatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mspatial_softArgmax3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m     \u001b[0mall_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsubXHVdu1eL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_keypoints(heatmap):\n",
        "   \n",
        "  val = np.argwhere(heatmap == np.max(heatmap))[0]\n",
        "  return val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BBaV32gu9Tc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1326d955-518e-4483-b0a9-452bcdc6a466"
      },
      "source": [
        "pred_example_heatmaps = model_final.predict(x_test1[0,:,:,:,:])\n",
        "pred_example_heatmaps[:,:,:,0,0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czMrFguroKXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new_heatmap = np.zeros(64*64*64*5).reshape(64,64,64,5)\n",
        "\n",
        "for i in range(32):\n",
        "  pred_example_heatmaps = model_final.predict(x_test1[i,:,:,:,:])\n",
        "  \n",
        "  #a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  #a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  #dd =  spatial_softArgmax3d(a)\n",
        "  #p = dd.numpy()\n",
        "  new_landmarks = []\n",
        "  for i in range(5):\n",
        "    img = pred_example_heatmaps[:,:,:,0,i]\n",
        "    img = img.reshape(64,64,64)\n",
        "    val = extract_keypoints(img)\n",
        "    new_landmarks.append(val)\n",
        "  \n",
        "  print(new_landmarks)\n",
        "  m = y_test1[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)\n",
        "  print(d)\n",
        "  print(np.abs(new_landmarks-d))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1awZ7ZQ6RuTt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "def calculate_MEE(model_final,x,y):\n",
        "  s_train1 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "    s_train1 = s_train1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  return s_train1/(len(x))\n",
        "\n",
        "def calculate_MEA(model_final,x,y):\n",
        "  s_train2 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    #a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    #a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    #dd =  spatial_softArgmax3d(a)*4.0\n",
        "    \n",
        "    pred_example_heatmaps = model_final.predict(x_test1[i,:,:,:,:])\n",
        "  \n",
        "  #a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    #a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    #dd =  spatial_softArgmax3d(a)\n",
        "    #p = dd.numpy()\n",
        "    d = []\n",
        "    for i in range(5):\n",
        "      img = pred_example_heatmaps[:,:,:,0,i]\n",
        "      img = img.reshape(64,64,64)\n",
        "      val = extract_keypoints(img)\n",
        "      d.append(val)\n",
        "    \n",
        "    \n",
        "    #p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "    #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "    #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "    s_train2 = s_train2 + np.mean((np.abs(d-dd)))\n",
        "    #for j in range(5):\n",
        "    #for j in range(5):\n",
        "      # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "  return s_train2/(len(x))\n",
        "\n",
        "\n",
        "def calculate_Acc(x,y):\n",
        "  count = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "  \n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "  return (count/(5*len(x)))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAC38J60R6fT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "5eec31a6-f6e7-4373-d513-2087cf28a451"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(3, True, 1)\n",
        "a1=0\n",
        "a2=0\n",
        "a3=0\n",
        "a4=0\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  x_train = x_data[train]\n",
        "  y_train = y_data[train]\n",
        "  x_val = x_data[val]\n",
        "  y_val = y_data[val]\n",
        "  a1 = a1 + calculate_MEA(model_final,x_train,y_train)\n",
        "  a2 = a2 + calculate_MEE(model_final,x_train,y_train)\n",
        "  a3 = a3 + calculate_MEA(model_final,x_val,y_val)\n",
        "  a4 = a4 + calculate_MEE(model_final,x_val,y_val)\n",
        "print(a1/3)\n",
        "print(a2/3)\n",
        "print(a3/3)\n",
        "print(a4/3)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_5:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "15.663430285960748\n",
            "32.78402265978951\n",
            "15.663639022261284\n",
            "32.78465998027094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4j7mWqZ7xVJH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b70bdcb8-63bf-4154-c624-a0f291a6f29b"
      },
      "source": [
        "print(calculate_MEA(model_final,x_test1,y_test1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78.99166870117188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxtC54G_pAoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b2fc5488-a35c-4f28-9d42-8a5ed831fcf6"
      },
      "source": [
        "print(calculate_MEA(model_final,x_test1,y_test1))\n",
        "print(calculate_MEE(model_final,x_test1,y_test1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53.86334574222565\n",
            "112.05819869041443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv5Rly9vpQfo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ee901809-35f3-49ee-9927-d85845326fb7"
      },
      "source": [
        "print(calculate_MEA(model_final,x_train,y_train))\n",
        "print(calculate_MEE(model_final,x_val,y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56.374605040619336\n",
            "112.81120995914235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIN-ijxtSAq6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "015895cc-1049-4774-9089-582065c5e750"
      },
      "source": [
        "print(calculate_MEA(model_final,x_test1,y_test1))\n",
        "print(calculate_MEE(model_final,x_test1,y_test1))\n",
        "print(calculate_MEA(model_final,x_test2,y_test2))\n",
        "print(calculate_MEE(model_final,x_test2,y_test2))\n",
        "print(calculate_MEA(model_final,x_test3,y_test3))\n",
        "print(calculate_MEE(model_final,x_test3,y_test3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_4:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "3.5441483557224274\n",
            "7.848307982087135\n",
            "3.455553639319635\n",
            "7.57251359570411\n",
            "3.6097556195169127\n",
            "7.9682602612477424\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eVDhj2Ihdiy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8cd6febd-0ac7-4c74-cdaf-5b32f15d3efe"
      },
      "source": [
        "print(calculate_MEA(model_final,x_test1,y_test1))\n",
        "print(calculate_MEE(model_final,x_test1,y_test1))\n",
        "print(calculate_MEA(model_final,x_test2,y_test2))\n",
        "print(calculate_MEE(model_final,x_test2,y_test2))\n",
        "print(calculate_MEA(model_final,x_test3,y_test3))\n",
        "print(calculate_MEE(model_final,x_test3,y_test3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.17659342288971\n",
            "31.39323192834854\n",
            "13.82221455727854\n",
            "30.29005438281644\n",
            "14.43902247806765\n",
            "31.87304104499097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vPU3dGSRyvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(3, True, 1)\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  x_train = x_data[train]\n",
        "  y_train = y_data[train]\n",
        "  x_val = x_data[val]\n",
        "  y_val = y_data[val]\n",
        "  print(calculate_MEA(model_final,x_train,y_train))\n",
        "  print(calculate_MEE(model_final,x_train,y_train))\n",
        "  print(calculate_MEA(model_final,x_val,y_val))\n",
        "  print(calculate_MEE(model_final,x_val,y_val))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NO_aiiaHMFOe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = create_model('/content/drive/My Drive/Database/Model_training_new/DA1/Fold1/epochs:150-val_loss:0.254.hdf5')\n",
        "model2 = create_model('/content/drive/My Drive/Database/Model_training_new/DA1/Fold2/epochs:099-val_loss:0.432.hdf5')\n",
        "model3 = create_model('/content/drive/My Drive/Database/Model_training_new/DA1/Fold3/epochs:146-val_loss:0.248.hdf5')\n",
        "#model4 = create_model('/content/drive/My Drive/Database/Model_training_5_new/DA1/Fold4/epochs:098-val_loss:0.613.hdf5')\n",
        "#model5 = create_model('/content/drive/My Drive/Database/Model_training_5_new/DA1/Fold5/epochs:085-val_loss:0.697.hdf5')\n",
        "model_list = [model1,model2,model3]#,model4,model5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b14Wo5S9N9iO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "ca2e092a-901b-4098-c168-7159492049f0"
      },
      "source": [
        "def cal_test_m(model):\n",
        "  metric = []\n",
        "  metric.append(model.evaluate(x_test1, y_test1, batch_size=1))\n",
        "  metric.append(model.evaluate(x_test2, y_test2, batch_size=1))\n",
        "  return metric\n",
        "sum1 = 0\n",
        "sum2 = 0\n",
        "sum3 = 0\n",
        "sum4 = 0\n",
        "for m in model_list:\n",
        "  m1 = cal_test_m(m)\n",
        "  print(m1)\n",
        "  sum1 = sum1 + m1[0][1]\n",
        "  sum2 = sum2 + m1[1][1]\n",
        "  sum3 = sum3 + m1[0][2]\n",
        "  sum4 = sum4 + m1[1][2]\n",
        "\n",
        "print(\"test 1 MAE: {}\".format(sum1/3))\n",
        "print(\"test 2 MAE: {}\".format(sum2/3))\n",
        "print(\"test 1 MEE: {}\".format(sum3/3))\n",
        "print(\"test 2 MEE: {}\".format(sum4/3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            "32/32 [==============================] - 7s 221ms/step - loss: 4.3395 - MAE: 4.2660 - MEE: 9.3224\n",
            "31/31 [==============================] - 7s 220ms/step - loss: 4.0170 - MAE: 4.2131 - MEE: 9.2005\n",
            "[[4.339524745941162, 4.265986442565918, 9.322407722473145], [4.016953468322754, 4.213137626647949, 9.20047664642334]]\n",
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 4.4751 - MAE: 4.2887 - MEE: 9.3032\n",
            "31/31 [==============================] - 7s 220ms/step - loss: 3.9931 - MAE: 4.1898 - MEE: 9.0339\n",
            "[[4.475107669830322, 4.288740158081055, 9.303190231323242], [3.99314284324646, 4.189825534820557, 9.03387451171875]]\n",
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 4.4745 - MAE: 4.3070 - MEE: 9.3883\n",
            "31/31 [==============================] - 7s 220ms/step - loss: 3.9099 - MAE: 4.1978 - MEE: 9.0093\n",
            "[[4.474514007568359, 4.307025909423828, 9.388280868530273], [3.9098994731903076, 4.1978230476379395, 9.00925350189209]]\n",
            "test 1 MAE: 4.287250836690267\n",
            "test 2 MAE: 4.200262069702148\n",
            "test 1 MEE: 9.33795960744222\n",
            "test 2 MEE: 9.081201553344727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hqcc4tNPH9g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "752c2db3-b762-47b7-d902-82109760694f"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "#metric_train = []\n",
        "#metric_test1 = []\n",
        "#metric_test2 = []\n",
        "#metric_val = []\n",
        "#His = []\n",
        "#model = []\n",
        "kfold = KFold(3, True, 1)\n",
        "t = []\n",
        "v = []\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  t.append(train)\n",
        "  v.append(train)\n",
        "def cal_train_m(model,i,t,v):\n",
        "  metric = []\n",
        "  x_train = x_data[t[i]]\n",
        "  y_train = y_data[t[i]]\n",
        "  x_val = x_data[v[i]]\n",
        "  y_val = y_data[v[i]]\n",
        "  metric.append(model.evaluate(x_train, y_train, batch_size=1))\n",
        "  metric.append(model.evaluate(x_val, y_val, batch_size=1))\n",
        "  return metric\n",
        "  \n",
        "sum1 = 0\n",
        "sum2 = 0\n",
        "sum3 = 0\n",
        "sum4 = 0\n",
        "count = 0\n",
        "for m in model_list:\n",
        "  #print(idx)\n",
        "  m1 = cal_train_m(m,count,t,v)\n",
        "  print(m1)\n",
        "  sum1 = sum1 + m1[0][1]\n",
        "  sum2 = sum2 + m1[1][1]\n",
        "  sum3 = sum3 + m1[0][2]\n",
        "  sum4 = sum4 + m1[1][2]\n",
        "  count = count+1\n",
        "print(\"train MAE: {}\".format(sum1/3))\n",
        "print(\"val MAE: {}\".format(sum2/3))\n",
        "print(\"train MEE: {}\".format(sum3/3))\n",
        "print(\"val MEE: {}\".format(sum4/3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "137/137 [==============================] - 31s 226ms/step - loss: 0.2540 - MAE: 1.1163 - MEE: 2.2541\n",
            "137/137 [==============================] - 31s 226ms/step - loss: 0.2540 - MAE: 1.1163 - MEE: 2.2541\n",
            "[[0.2540019750595093, 1.116297721862793, 2.2541403770446777], [0.2540019750595093, 1.116297721862793, 2.2541403770446777]]\n",
            "137/137 [==============================] - 31s 226ms/step - loss: 0.4320 - MAE: 1.4977 - MEE: 3.0046\n",
            "137/137 [==============================] - 31s 226ms/step - loss: 0.4320 - MAE: 1.4977 - MEE: 3.0046\n",
            "[[0.4319863021373749, 1.4976862668991089, 3.0046379566192627], [0.4319863021373749, 1.4976862668991089, 3.0046379566192627]]\n",
            "138/138 [==============================] - 31s 226ms/step - loss: 0.2484 - MAE: 1.0864 - MEE: 2.1819\n",
            "138/138 [==============================] - 31s 226ms/step - loss: 0.2484 - MAE: 1.0864 - MEE: 2.1819\n",
            "[[0.24836255609989166, 1.0863871574401855, 2.1818795204162598], [0.24836255609989166, 1.0863871574401855, 2.1818795204162598]]\n",
            "train MAE: 1.233457048734029\n",
            "val MAE: 1.233457048734029\n",
            "train MEE: 2.4802192846934\n",
            "val MEE: 2.4802192846934\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVEM6NmTPq4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def cal_whole(model,x,y,i,t,v):\n",
        "  m1=[]\n",
        "  m2=[]\n",
        "  m1.append(calculate_MEA(model,x_data[t[i]],y_data[t[i]]))\n",
        "  m1.append(calculate_MEE(model,x_data[t[i]],y_data[t[i]]))\n",
        "  m2.append(calculate_MEA(model,x_data[v[i]],y_data[v[i]]))\n",
        "  m2.append(calculate_MEE(model,x_data[v[i]],y_data[v[i]]))\n",
        "  return [m1,m2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d7D6AoKhPwx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "c7b09e59-119c-4d5b-e980-09516c8e5fb6"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "metric_train = []\n",
        "metric_test1 = []\n",
        "metric_test2 = []\n",
        "metric_val = []\n",
        "\n",
        "\n",
        "mea_train=0\n",
        "mea_val=0\n",
        "mee_train=0\n",
        "mee_val=0\n",
        "acc_train=0\n",
        "acc_val=0\n",
        "\n",
        "for i,m in enumerate(model_list):\n",
        "  m1 = cal_whole(m,x_data,y_data,i,t,v)\n",
        "\n",
        "  mea_val =mea_val + m1[1][0]\n",
        "  mea_train =mea_train + m1[0][0]\n",
        "  mee_val =mee_val + m1[1][1]\n",
        "  mee_train =mee_train + m1[0][1]\n",
        "\n",
        "\n",
        "print(\"Training : \")\n",
        "print(\"MEA : {}\".format(mea_train/3))\n",
        "print(\"MEE : {}\".format(mee_train/3))\n",
        "\n",
        "print(\"Validation : \")\n",
        "print(\"MEA : {}\".format(mea_val/3))\n",
        "print(\"MEE : {}\".format(mee_val/3))\n",
        "\n",
        "   \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_2:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_3:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 64, 64, 64, 1) for input Tensor(\"input_4:0\", shape=(None, 64, 64, 64, 1), dtype=float32), but it was called on an input with incompatible shape (32, 64, 64, 1, 1).\n",
            "Training : \n",
            "MEA : 16.013557313472948\n",
            "MEE : 34.21490520874247\n",
            "Validation : \n",
            "MEA : 16.013557313472948\n",
            "MEE : 34.21490520874247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr2r5ENsRSEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "def calculate_MEE(model_final,x,y):\n",
        "  s_train1 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "    s_train1 = s_train1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  return s_train1/(len(x))\n",
        "\n",
        "def calculate_MEA(model_final,x,y):\n",
        "  s_train2 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "    #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "    #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "    s_train2 = s_train2 + np.mean((np.abs(d-dd)))\n",
        "    #for j in range(5):\n",
        "    #for j in range(5):\n",
        "      # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "  return s_train2/(len(x))\n",
        "\n",
        "\n",
        "def calculate_Acc(x,y):\n",
        "  count = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "  \n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "  return (count/(5*len(x)))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCZyh-1EQcxy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_test1(m):\n",
        "  m1 = []\n",
        "  m2 = []\n",
        "  m1.append(calculate_MEA(m,x_test1,y_test1))\n",
        "  m1.append(calculate_MEE(m,x_test1,y_test1))\n",
        "  m2.append(calculate_MEA(m,x_test2,y_test2))\n",
        "  m2.append(calculate_MEE(m,x_test2,y_test2))\n",
        "  return [m1,m2]\n",
        "  \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rXwRVaZQdkf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "62b1a170-b5b4-498d-b254-063e7239db2d"
      },
      "source": [
        "sum1 = 0\n",
        "sum2 = 0\n",
        "sum3 = 0\n",
        "sum4 = 0\n",
        "for m in model_list:\n",
        "  m1 = cal_test1(m)\n",
        "  print(m1)\n",
        "  sum1 = sum1 + m1[0][0]\n",
        "  sum2 = sum2 + m1[1][0]\n",
        "  sum3 = sum3 + m1[0][1]\n",
        "  sum4 = sum4 + m1[1][1]\n",
        "\n",
        "print(\"test 1 MAE: {}\".format(sum1/3))\n",
        "print(\"test 2 MAE: {}\".format(sum2/3))\n",
        "print(\"test 1 MEE: {}\".format(sum3/3))\n",
        "print(\"test 2 MEE: {}\".format(sum4/3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[13.232284277677536, 30.181258976459503], [13.033370387169622, 29.88572169888404]]\n",
            "[[12.72087299823761, 29.117307603359222], [12.45360537498228, 28.622902285668157]]\n",
            "[[15.047671854496002, 33.686164140701294], [15.121543853513655, 33.67488485766995]]\n",
            "test 1 MAE: 13.666943043470383\n",
            "test 2 MAE: 13.536173205221852\n",
            "test 1 MEE: 30.99491024017334\n",
            "test 2 MEE: 30.727836280740718\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kWXFUE1as38",
        "colab_type": "text"
      },
      "source": [
        "# **Model Ensemble**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iXMefdyawVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = np.array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tresult = np.mean(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\treturn result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbeyxIplazAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model11 = create_model('/content/drive/My Drive/Database/Model_training_5_new/DA1/Fold1/epochs:094-val_loss:0.637.hdf5')\n",
        "model22 = create_model('/content/drive/My Drive/Database/Model_training_5_new/DA1/Fold1/epochs:089-val_loss:0.648.hdf5')\n",
        "model33 = create_model('/content/drive/My Drive/Database/Model_training_5_new/DA1/Fold1/epochs:094-val_loss:0.637.hdf5')\n",
        "\n",
        "model_list1 = [model11,model22,model33]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1pvOotYocF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_list1 = model_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLVAjs_pa-Lf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "def calculate_MEE(models,x,y):\n",
        "  s_train1 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = ensemble_predictions(models,x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "    s_train1 = s_train1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  return s_train1/(len(x))\n",
        "\n",
        "def calculate_MEA(models,x,y):\n",
        "  s_train2 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = ensemble_predictions(models,x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "    #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "    #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "    s_train2 = s_train2 + np.mean((np.abs(d-dd)))\n",
        "    #for j in range(5):\n",
        "    #for j in range(5):\n",
        "      # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "  return s_train2/(len(x))\n",
        "\n",
        "\n",
        "def calculate_Acc(x,y):\n",
        "  count = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "  \n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "  return (count/(5*len(x)))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx0sk2PZbEWy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b5732399-4525-40c8-e831-b688d909995b"
      },
      "source": [
        "print(calculate_MEA(model_list1,x_test1,y_test1))\n",
        "print(calculate_MEE(model_list1,x_test1,y_test1))\n",
        "print(calculate_MEA(model_list1,x_test2,y_test2))\n",
        "print(calculate_MEE(model_list1,x_test2,y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.247525125741959\n",
            "29.971638202667236\n",
            "13.076736542486376\n",
            "29.661807767806515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3YLPwuMhaEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from scipy.stats import gmean\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = np.array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tresult = yhats[0]*0.5+yhats[1]*0.5+yhats[2]*0.5\n",
        "\t# argmax across classes\n",
        "\treturn result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFR20MGYhfV5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9d858f27-723f-464e-a9b4-635807f598bf"
      },
      "source": [
        "print(calculate_MEA(model_list1,x_test1,y_test1))\n",
        "print(calculate_MEE(model_list1,x_test1,y_test1))\n",
        "print(calculate_MEA(model_list1,x_test2,y_test2))\n",
        "print(calculate_MEE(model_list1,x_test2,y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.907082319259644\n",
            "29.095909237861633\n",
            "12.78510533609698\n",
            "28.80198072618054\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNEc3X3hMHzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "#metric_train = []\n",
        "#metric_test1 = []\n",
        "#metric_test2 = []\n",
        "#metric_val = []\n",
        "#His = []\n",
        "#model = []\n",
        "kfold = KFold(5, True, 1)\n",
        "t = []\n",
        "v = []\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  t.append(train)\n",
        "  v.append(train)\n",
        "\n",
        "for i in range(len(t)):  \n",
        "  print(\"FOLD : {}\".format(i+1))\n",
        "  x_train = x_data[t[i]]\n",
        "  y_train = y_data[t[i]]\n",
        "  x_val = x_data[v[i]]\n",
        "  y_val = y_data[v[i]]\n",
        "  #print(y_train.shape)\n",
        "  History=model_final.fit(x_train, y_train,\n",
        "            batch_size=batch_size, shuffle=True, validation_data=(x_val,y_val),\n",
        "            epochs=50,\n",
        "            verbose=1,callbacks=[tensorboard_callback,es])#,checkpoint])\n",
        "  #metric_train.append(model_final.evaluate(x_train, y_train, batch_size=1))\n",
        "  #metric_val.append(model_final.evaluate(x_val, y_val, batch_size=1))\n",
        "  #metric_test1.append(model_final.evaluate(x_test1, y_test1, batch_size=1))\n",
        "  #metric_test2.append(model_final.evaluate(x_test2, y_test2, batch_size=1))\n",
        "  #His.append(History)\n",
        "  #model.append(model_final)\n",
        "\n",
        "  del x_train\n",
        "  del y_train\n",
        "  del x_val\n",
        "  del y_val\n",
        "  K.clear_session()\n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGYYfV2oujOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  del x_train\n",
        "  del y_train\n",
        "  del x_val\n",
        "  del y_val\n",
        "  K.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYmq1iMheQET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del x_train\n",
        "del y_train\n",
        "del x_val\n",
        "del y_val\n",
        "del x_test1\n",
        "del x_test2\n",
        "del y_test1\n",
        "del y_test2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_0eduK4KNOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "metric_train = []\n",
        "metric_test = []\n",
        "metric_val = []\n",
        "His = []\n",
        "model = []\n",
        "kfold = KFold(5, True, 1)\n",
        "saver=tf.train.Saver()\n",
        "save_path='/content/drive/My Drive/Database/Model_training_5/DA1/new_train/'\n",
        "\n",
        "saver.save(sess=session,save_path=save_path)\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  x_train = x_data[train]\n",
        "  y_train = y_data[train]\n",
        "  x_val = x_data[val]\n",
        "  y_val = y_data[val]\n",
        "  #print(y_train.shape)\n",
        "  History=model_final.fit(x_train, y_train,\n",
        "            batch_size=batch_size, shuffle=True, validation_data=(x_val,y_val),\n",
        "            epochs=100,\n",
        "            verbose=1,callbacks=[tensorboard_callback,es,cp_callback])\n",
        "  metric_train.append(model_final.evaluate(x_train, y_train, batch_size=1))\n",
        "  metric_val.append(model_final.evaluate(x_val, y_val, batch_size=1))\n",
        "  metric_test.append(model_final.evaluate(x_test, y_test, batch_size=1))\n",
        "  His.append(History)\n",
        "  model.append(model_final)\n",
        "\n",
        "  del x_train\n",
        "  del y_train\n",
        "  del x_val\n",
        "  del y_val\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpUtzYzCWDhE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c499acc3-44b6-49e3-8de2-0a628797ae8b"
      },
      "source": [
        "model_final.evaluate(x_test1, y_test1, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 64, 64, 64, 5)\n",
            "(1, 64, 64, 64, 5)\n",
            "32/32 [==============================] - 7s 220ms/step - loss: 1.4372 - MAE: 4.3115 - MEE: 9.4317\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.4371603727340698, 4.31148099899292, 9.431658744812012]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzxSPcZQV-wD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cb2829e0-4731-4032-f0c5-3a26af463066"
      },
      "source": [
        "model_final.evaluate(x_test2, y_test2, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31/31 [==============================] - 7s 220ms/step - loss: 1.3918 - MAE: 4.1754 - MEE: 9.0313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.3917988538742065, 4.175395965576172, 9.031316757202148]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHq7tijuV4et",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8d16fd48-9896-4196-90b4-b5fd85f80f8d"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "metric_train = []\n",
        "metric_val = []\n",
        "kfold = KFold(5, True, 1)\n",
        "\n",
        "for train, val in kfold.split(x_data):\n",
        "  x_train = x_data[train]\n",
        "  y_train = y_data[train]\n",
        "  x_val = x_data[val]\n",
        "  y_val = y_data[val]\n",
        "  metric_train.append(model_final.evaluate(x_train, y_train, batch_size=1))\n",
        "  metric_val.append(model_final.evaluate(x_val, y_val, batch_size=1))\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 37s 226ms/step - loss: 0.6369 - MAE: 1.9106 - MEE: 4.0069\n",
            "42/42 [==============================] - 9s 221ms/step - loss: 0.7463 - MAE: 2.2389 - MEE: 4.6087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7BcD86OV7wo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e764c1ab-dbf1-4af8-8f37-64585608efd6"
      },
      "source": [
        "metric_train\n",
        "print(np.mean(metric_train,axis=0))\n",
        "metric_val\n",
        "print(np.mean(metric_val,axis=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.49332144 1.47996447 3.10374207]\n",
            "[0.49346397 1.48039179 3.10457358]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sovlBp2LWh7c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "def calculate_MEE(x,y):\n",
        "  s_train1 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "    s_train1 = s_train1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  return s_train1/(len(x))\n",
        "\n",
        "def calculate_MEA(x,y):\n",
        "  s_train2 = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "    #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "    #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "    s_train2 = s_train2 + np.mean((np.abs(d-dd)))\n",
        "    #for j in range(5):\n",
        "    #for j in range(5):\n",
        "      # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "  return s_train2/(len(x))\n",
        "\n",
        "\n",
        "def calculate_Acc(x,y):\n",
        "  count = 0\n",
        "  for i in range(len(x)):\n",
        "    pred_example_heatmaps = model_final.predict(x[i,:,:,:,:])\n",
        "    a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "    a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "    dd =  spatial_softArgmax3d(a)*4.0\n",
        "    p = dd.numpy()\n",
        "    \n",
        "    m = y[i,:,:,:,:]\n",
        "    m = m.reshape(1,64,64,64,5)\n",
        "    b = tf.convert_to_tensor(m, np.float32)\n",
        "    d =  spatial_softArgmax3d(b)*4.0\n",
        "  \n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "  return (count/(5*len(x)))*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpN26VaLWjHZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "964ffe2f-4752-4f6f-d927-cacec65021e4"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "metric_train = []\n",
        "metric_test1 = []\n",
        "metric_test2 = []\n",
        "metric_val = []\n",
        "His = []\n",
        "model = []\n",
        "kfold = KFold(5, True, 1)\n",
        "t = []\n",
        "v = []\n",
        "\n",
        "mea_train=0\n",
        "mea_val=0\n",
        "mee_train=0\n",
        "mee_val=0\n",
        "acc_train=0\n",
        "acc_val=0\n",
        "for train, val in kfold.split(x_data):\n",
        "  mea_val =mea_val + calculate_MEA(x_data[val],y_data[val])\n",
        "  mea_train =mea_train + calculate_MEA(x_data[train],y_data[train])\n",
        "  mee_val =mee_val + calculate_MEE(x_data[val],y_data[val])\n",
        "  mee_train =mee_train + calculate_MEE(x_data[train],y_data[train])\n",
        "  acc_train = acc_train + calculate_Acc(x_data[train],y_data[train])\n",
        "  acc_val = acc_val + calculate_Acc(x_data[val],y_data[val])\n",
        "\n",
        "\n",
        "print(\"Training : \")\n",
        "print(\"MEA : {}\".format(mea_train/5))\n",
        "print(\"MEE : {}\".format(mee_train/5))\n",
        "print(\"Accuracy : {}\".format(acc_train/5))\n",
        "\n",
        "print(\"Validation : \")\n",
        "print(\"MEA : {}\".format(mea_val/5))\n",
        "print(\"MEE : {}\".format(mee_val/5))\n",
        "print(\"Accuracy : {}\".format(acc_val/5))\n",
        "   \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training : \n",
            "MEA : 17.083825490920525\n",
            "MEE : 36.52613214716943\n",
            "Accuracy : 0.0\n",
            "Validation : \n",
            "MEA : 17.08915564352073\n",
            "MEE : 36.53343373142468\n",
            "Accuracy : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIU1mEzTYa_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(calculate_MEE(x_test1,y_test1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F70WjjAhTVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(calculate_MEA(x_test2,y_test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtCUsRvNYdDL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35fc1611-d85f-4822-9e93-4c9b1292d80a"
      },
      "source": [
        "print(calculate_MEE(x_test2,y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28.680103178947203\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWVqSl-chVHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e38dad9-35d7-4308-d4f6-a499f0bd54a9"
      },
      "source": [
        "print(calculate_MEA(x_test1,y_test1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12.784093737602234\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pm89RCaNzRVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv *_6.txt '/content/drive/My Drive/Database/Aug_img_mrk/landmarks'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gB4oWcZg-rG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "378dbe9b-fb63-4007-80ce-0384df9b9da5"
      },
      "source": [
        "for i in range(103):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  print(np.abs(dd-d))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  5.8448563 131.99997   106.9924   ]\n",
            " [ 22.112747    4.6430054  44.336052 ]\n",
            " [ 23.645866  139.93869    44.05522  ]\n",
            " [ 20.000008   68.         20.       ]\n",
            " [ 16.212326   78.15936   103.993546 ]]\n",
            "[[ 24.78543   136.         81.26836  ]\n",
            " [ 22.149635   97.2527     34.51142  ]\n",
            " [ 71.81888    79.3264     61.118927 ]\n",
            " [ 39.159744   64.62398     2.0065155]\n",
            " [  5.3809814  47.77205    31.108566 ]]\n",
            "[[  4.3425674 119.99994   126.46086  ]\n",
            " [ 76.         72.          4.       ]\n",
            " [ 51.999954  127.99992    31.977867 ]\n",
            " [ 20.         72.         32.       ]\n",
            " [  9.563995   78.24074   100.00011  ]]\n",
            "[[ 47.942566  128.         40.003098 ]\n",
            " [ 40.84153    96.56537    11.995583 ]\n",
            " [ 31.71164    90.58647   127.36461  ]\n",
            " [ 18.30568    67.67999    26.877777 ]\n",
            " [  3.5523605 120.21475   104.00006  ]]\n",
            "[[ 29.95575   132.00003    16.024033 ]\n",
            " [ 71.99095   107.979324   30.925327 ]\n",
            " [ 51.977356  147.9992     27.999603 ]\n",
            " [ 31.914131   72.01135    19.993683 ]\n",
            " [  4.1411743  72.01819   104.       ]]\n",
            "[[  3.2987747  128.00002    134.22829   ]\n",
            " [  0.50927734  11.27861     57.850266  ]\n",
            " [ 32.94078     72.6288      91.26677   ]\n",
            " [ 24.001007    67.99579     11.996796  ]\n",
            " [  4.065094     8.839142   111.99808   ]]\n",
            "[[ 31.438362 127.999985  66.462234]\n",
            " [ 28.219582  38.729477  51.914955]\n",
            " [ 51.99353  135.99928   32.00026 ]\n",
            " [ 29.245712  16.392975  68.20429 ]\n",
            " [  4.077057  73.39993  103.99962 ]]\n",
            "[[  0.14266205 135.99998     92.46655   ]\n",
            " [ 15.512039     1.894577    42.46356   ]\n",
            " [ 59.043304    72.81773     88.95532   ]\n",
            " [  0.24545288  49.927002    27.664413  ]\n",
            " [ 10.622002     3.4434662  103.98901   ]]\n",
            "[[ 37.17964   155.99997    50.445908 ]\n",
            " [ 22.299011  124.361755   31.245827 ]\n",
            " [ 22.982162   99.808304   77.55774  ]\n",
            " [ 20.000374   71.99843    12.001709 ]\n",
            " [  3.7122421   8.237961  107.78406  ]]\n",
            "[[ 16.66536  139.99995   61.891754]\n",
            " [ 55.894287 115.5683    43.477245]\n",
            " [ 16.       148.        56.      ]\n",
            " [ 67.99925   92.002594  32.00386 ]\n",
            " [  4.33255    6.392502 107.99985 ]]\n",
            "[[  0.7581711 128.         87.78995  ]\n",
            " [ 34.846382   72.09343    44.060936 ]\n",
            " [ 67.92572    99.95093    80.11276  ]\n",
            " [ 55.045998   91.7684     54.88118  ]\n",
            " [ 19.486954  114.96498   104.00006  ]]\n",
            "[[ 27.0784    143.99979    83.259766 ]\n",
            " [ 52.12387     3.7422256  43.821354 ]\n",
            " [ 60.08983    65.20775    79.77995  ]\n",
            " [ 19.795486   63.996872   12.015472 ]\n",
            " [  2.9103622  25.463394  115.88861  ]]\n",
            "[[  0.18222046 139.99998     83.19176   ]\n",
            " [ 35.813812    30.047775    28.686867  ]\n",
            " [ 51.182938    68.97017     73.184586  ]\n",
            " [ 28.687561    70.07677      7.155365  ]\n",
            " [  2.713272     0.7214966  107.98987   ]]\n",
            "[[ 25.783684   135.99992     87.71692   ]\n",
            " [  4.663513    81.31058     45.420692  ]\n",
            " [ 49.671204    75.00435     91.259155  ]\n",
            " [ 35.00647     71.69081      0.27967834]\n",
            " [  0.58117676   6.2194977   99.89691   ]]\n",
            "[[ 15.901077  127.999985   86.85466  ]\n",
            " [ 24.008255    7.9987946  59.993256 ]\n",
            " [ 67.809845   76.18785    88.38013  ]\n",
            " [ 59.502914   95.65399     3.670227 ]\n",
            " [ 17.435928   71.49965   108.00021  ]]\n",
            "[[ 33.127983 135.99997   95.26448 ]\n",
            " [ 75.98008   11.57412   15.994545]\n",
            " [ 32.487038 143.22606   26.2304  ]\n",
            " [ 40.15909   37.713562  10.988831]\n",
            " [  9.515289  24.360596  99.73923 ]]\n",
            "[[ 31.176292  124.         92.1062   ]\n",
            " [ 17.537888   86.57744     1.3892746]\n",
            " [  2.2883759  81.56413    89.9877   ]\n",
            " [ 63.806458   12.13913    19.947342 ]\n",
            " [  3.6062164   2.2859192  99.984924 ]]\n",
            "[[ 30.488327  127.99994    96.162445 ]\n",
            " [ 13.542786   62.569717   26.584198 ]\n",
            " [ 48.458267   75.5605     91.427155 ]\n",
            " [  4.488632   74.707306    8.       ]\n",
            " [  3.4307404   5.589325  107.99846  ]]\n",
            "[[ 63.98918   128.00002    83.51445  ]\n",
            " [ 16.181839   10.556496   56.751907 ]\n",
            " [ 24.375137   80.1302     16.888062 ]\n",
            " [ 10.782242    0.8639984  46.816902 ]\n",
            " [  6.846878   65.26883   107.99788  ]]\n",
            "[[  2.2911835 151.9999     66.29242  ]\n",
            " [ 28.734543  102.0795     46.182926 ]\n",
            " [ 60.48886    75.01683    90.95601  ]\n",
            " [ 19.914627   67.98396    23.939621 ]\n",
            " [ 10.802551   77.202774   99.996185 ]]\n",
            "[[  3.4377213 136.00003    89.33574  ]\n",
            " [ 53.7574      2.9412994   8.6482315]\n",
            " [ 42.2722     97.42621    81.983536 ]\n",
            " [ 59.46817     4.7659836  11.797241 ]\n",
            " [  2.456787   28.133575  107.739136 ]]\n",
            "[[ 44.27884  136.        66.97354 ]\n",
            " [ 55.999992   8.232155  35.99982 ]\n",
            " [ 51.970108 147.86871   36.062897]\n",
            " [ 75.99989   83.971405  35.971863]\n",
            " [  8.380791  81.2614   100.000046]]\n",
            "[[8.5414124e+00 1.4399998e+02 5.4246552e+01]\n",
            " [5.4954254e+01 1.1738725e+02 5.1124104e+01]\n",
            " [6.7041237e+01 8.9979355e+01 7.2493622e+01]\n",
            " [5.6020828e+01 9.0591431e-02 8.0127563e+00]\n",
            " [3.2414246e-01 8.8563766e+00 1.0799956e+02]]\n",
            "[[  2.5725021 143.99998   112.93555  ]\n",
            " [ 59.99948    79.99405     8.000145 ]\n",
            " [ 38.14061   113.228485   80.90633  ]\n",
            " [ 31.96135    68.00223    19.99472  ]\n",
            " [  5.3010864  15.151138  107.99904  ]]\n",
            "[[  9.9348755  140.          74.70398   ]\n",
            " [ 55.985016     3.9847336   39.99987   ]\n",
            " [ 40.723877   146.93509      4.848976  ]\n",
            " [ 16.460571    41.25995      5.333435  ]\n",
            " [  0.29367065  75.43826     99.997055  ]]\n",
            "[[  7.680313  132.00002    83.15918  ]\n",
            " [ 18.402939   22.400513   13.072067 ]\n",
            " [ 32.654045   85.22583    85.40741  ]\n",
            " [ 16.912811   68.918335   19.07106  ]\n",
            " [  2.4385605   4.986038  111.993866 ]]\n",
            "[[ 17.632645  148.00002    93.31766  ]\n",
            " [  7.6709595  10.013412   44.287952 ]\n",
            " [ 16.531662  155.3974     79.98387  ]\n",
            " [  5.425598  131.13533   113.891464 ]\n",
            " [  1.6666336  16.936813  108.00046  ]]\n",
            "[[ 41.14981   131.99997    99.581406 ]\n",
            " [ 44.03241     3.493744   37.555817 ]\n",
            " [  0.5216751 111.14841    65.51456  ]\n",
            " [ 23.935478   63.472107   35.905334 ]\n",
            " [  2.8108673 113.36981   107.99971  ]]\n",
            "[[ 26.469124   135.99998     88.91907   ]\n",
            " [ 59.99617      2.8972626   32.00257   ]\n",
            " [ 39.188873   116.31476     87.62981   ]\n",
            " [ 48.007736    11.79039      0.30204773]\n",
            " [  9.844147    50.536224   107.98663   ]]\n",
            "[[  1.1862183 151.99997    58.60051  ]\n",
            " [ 32.        128.         24.       ]\n",
            " [ 13.373581  144.40761    43.284363 ]\n",
            " [ 78.43555    78.77571    49.538345 ]\n",
            " [ 44.43103   147.47368    59.988235 ]]\n",
            "[[3.9851143e+01 1.2800000e+02 2.8296143e+01]\n",
            " [7.5999985e+01 1.9998566e+01 3.1089783e-02]\n",
            " [3.0734268e+01 1.1848921e+02 5.6358719e+01]\n",
            " [3.9138214e+01 3.8094788e+00 2.4127228e+01]\n",
            " [5.6129456e+00 4.2384644e+01 1.0370059e+02]]\n",
            "[[ 35.96943   131.99997   111.99411  ]\n",
            " [ 75.99036    69.50932     4.0189667]\n",
            " [ 41.069458  140.00002    64.88783  ]\n",
            " [ 12.000114   99.999756   59.999817 ]\n",
            " [  7.9342957 131.9261    103.99994  ]]\n",
            "[[2.3218140e+01 1.3599998e+02 8.9631699e+01]\n",
            " [4.6181747e+01 1.1679236e+02 3.0944328e+01]\n",
            " [2.5470306e+01 1.1636383e+02 5.4233398e+01]\n",
            " [3.1994446e+01 7.9806503e+01 1.5644455e+01]\n",
            " [6.8038940e-02 8.4869461e+01 9.9998489e+01]]\n",
            "[[3.19998093e+01 1.40000015e+02 2.00003586e+01]\n",
            " [2.59375229e+01 7.52410889e-02 5.11516647e+01]\n",
            " [4.79303894e+01 7.21407928e+01 8.39382324e+01]\n",
            " [3.67088699e+01 6.11504364e+01 1.82458496e+00]\n",
            " [2.41943359e-01 5.31649780e+00 1.07990204e+02]]\n",
            "[[  7.2734375 135.99995   101.04123  ]\n",
            " [  6.2988586 115.92317    83.93309  ]\n",
            " [ 72.6405     94.80795    57.121338 ]\n",
            " [ 59.90657     4.005417    3.9208984]\n",
            " [  8.462738   56.70645   108.00017  ]]\n",
            "[[2.25669708e+01 1.31999985e+02 1.13214417e+02]\n",
            " [5.19026184e+01 9.36965942e-02 3.99854202e+01]\n",
            " [2.38280792e+01 1.39629761e+02 9.11057587e+01]\n",
            " [2.09233093e+01 3.27351074e+01 1.00377655e+01]\n",
            " [9.82062531e+00 1.01862366e+02 1.12000275e+02]]\n",
            "[[ 38.466377  119.99994    19.482903 ]\n",
            " [ 33.23375    54.407806    9.492264 ]\n",
            " [  0.5244751 131.26558    29.509544 ]\n",
            " [ 33.024635   59.228302   40.57025  ]\n",
            " [ 34.69763    68.00214   103.999985 ]]\n",
            "[[ 13.478073  120.00015    27.691177 ]\n",
            " [ 84.00003     0.         11.999992 ]\n",
            " [ 34.93692    68.475555   81.61478  ]\n",
            " [ 14.140015   63.53041    22.042664 ]\n",
            " [  6.6111603 117.903366  123.99809  ]]\n",
            "[[ 26.276596  140.00003    59.326767 ]\n",
            " [ 66.9133    114.54382     8.183006 ]\n",
            " [ 66.17259    82.02672    74.11856  ]\n",
            " [ 27.409332    1.9904099  15.154175 ]\n",
            " [  2.2895432  13.499741  107.46185  ]]\n",
            "[[ 43.982193 155.99998   16.00486 ]\n",
            " [ 63.274124   8.09465   13.286026]\n",
            " [ 54.309433  61.23993   95.425995]\n",
            " [ 47.999985  59.859497  12.      ]\n",
            " [ 42.80275  138.12888   80.15935 ]]\n",
            "[[ 14.608414  151.99985    76.93733  ]\n",
            " [ 43.78743     2.6902847  44.649506 ]\n",
            " [ 63.93544    76.0172     92.008575 ]\n",
            " [ 31.436035   56.379974    1.6938019]\n",
            " [ 28.717728    2.067894   40.15306  ]]\n",
            "[[ 35.264496  135.99997    52.180435 ]\n",
            " [  9.98452    99.22032    35.48104  ]\n",
            " [ 27.313583   93.13223    65.10321  ]\n",
            " [ 26.055176   24.331512   17.569366 ]\n",
            " [  3.9641647  19.943405  103.99982  ]]\n",
            "[[ 43.527054 156.00006   28.682083]\n",
            " [ 54.37108    4.428192  43.924335]\n",
            " [ 55.62799   69.26581   80.933075]\n",
            " [ 20.08377   71.85104   23.731384]\n",
            " [ 19.92421   72.016266 103.99808 ]]\n",
            "[[ 21.312714   135.99997    105.93034   ]\n",
            " [  7.997574    99.957245    55.98562   ]\n",
            " [ 58.799133   118.22949     47.84633   ]\n",
            " [ 30.296082    70.31259     12.053314  ]\n",
            " [  0.15094757  80.02919    108.00009   ]]\n",
            "[[ 18.811668  135.99997    64.42328  ]\n",
            " [ 47.975708  111.99724    24.00293  ]\n",
            " [ 44.56552   146.25256    53.02672  ]\n",
            " [ 63.788406    0.2845459  19.794006 ]\n",
            " [  9.755478    3.431137   89.010376 ]]\n",
            "[[ 13.477692   132.00002     54.685997  ]\n",
            " [ 35.45272      2.8753128   70.02941   ]\n",
            " [ 29.860634    64.15445    127.965775  ]\n",
            " [  0.25587463  69.98334     19.4702    ]\n",
            " [ 16.167763   110.759796   111.99771   ]]\n",
            "[[ 23.618423   139.99995     76.541016  ]\n",
            " [ 58.393707     3.0943604   27.227242  ]\n",
            " [ 55.88063     88.765686    76.10997   ]\n",
            " [ 63.91713      3.8991776   23.802597  ]\n",
            " [  0.14370728  21.346863   107.83945   ]]\n",
            "[[ 55.59819   139.99997    63.045746 ]\n",
            " [ 64.36004     0.4009018  12.832726 ]\n",
            " [ 62.786026   75.77405    83.86403  ]\n",
            " [ 51.846443    4.4520264   3.9396362]\n",
            " [ 39.33934   125.91986     1.6754456]]\n",
            "[[  7.2670746 159.99998    24.227379 ]\n",
            " [ 27.658089  125.1187     15.376297 ]\n",
            " [ 60.638794   97.01849    89.90051  ]\n",
            " [ 23.643417   76.605835   30.610199 ]\n",
            " [ 31.032951  147.99455   111.967636 ]]\n",
            "[[ 41.65129   152.         27.22065  ]\n",
            " [ 19.218254    5.7627945  47.87244  ]\n",
            " [ 33.93051   138.1897     26.799301 ]\n",
            " [ 25.185074   34.19449    62.665237 ]\n",
            " [ 15.849861   99.36478   108.00023  ]]\n",
            "[[  6.3638    128.         34.84195  ]\n",
            " [ 32.341995   46.11351    20.653938 ]\n",
            " [ 31.997467   91.99997   119.99919  ]\n",
            " [  2.1051788 103.874084   40.62908  ]\n",
            " [  3.6048584  71.99516   104.00017  ]]\n",
            "[[ 39.12755   135.99997   106.72386  ]\n",
            " [ 15.077538  102.97888    34.621216 ]\n",
            " [ 31.302185  113.93698    45.226044 ]\n",
            " [ 27.997559   75.99301    19.994644 ]\n",
            " [  2.7753296  80.24086   104.00008  ]]\n",
            "[[ 28.467674  135.99997   105.765656 ]\n",
            " [  2.429268   18.634811   82.34558  ]\n",
            " [ 52.622833   75.01236    86.19452  ]\n",
            " [ 23.999985   95.88542     8.000793 ]\n",
            " [  2.1783905  69.98651   103.99927  ]]\n",
            "[[ 49.74826   136.00002    14.935471 ]\n",
            " [ 10.791168    4.3320465  40.4829   ]\n",
            " [ 22.704742  120.45894    58.36737  ]\n",
            " [ 25.729004    5.0206223  66.89887  ]\n",
            " [  1.8562927  80.456345   96.00072  ]]\n",
            "[[ 41.788345  152.         83.01854  ]\n",
            " [ 70.4534      3.3581238  23.354889 ]\n",
            " [ 67.99988    63.99997    88.00008  ]\n",
            " [ 55.919006    4.0075607   4.0575867]\n",
            " [  8.833099   34.31343    97.862015 ]]\n",
            "[[ 29.287903  135.99998    27.777298 ]\n",
            " [ 72.        112.000015   35.99998  ]\n",
            " [ 63.99997    92.00102    67.99994  ]\n",
            " [ 15.172882   36.549347   10.412827 ]\n",
            " [  2.8281784  83.45181   108.00073  ]]\n",
            "[[ 24.292122 128.        49.242645]\n",
            " [ 41.95961   86.06386   40.311848]\n",
            " [ 71.16983   91.250244  99.96007 ]\n",
            " [ 23.965042  70.66054   23.929825]\n",
            " [ 13.063034  91.37923  100.00174 ]]\n",
            "[[ 63.49951   143.99997    83.3219   ]\n",
            " [ 36.157463    3.0798264   9.03096  ]\n",
            " [ 16.722168  143.6751     62.275818 ]\n",
            " [ 43.950302   27.983376   63.99254  ]\n",
            " [  2.252243   32.604996  109.43773  ]]\n",
            "[[ 61.991516 132.        92.07762 ]\n",
            " [ 75.896576  39.68744   12.211327]\n",
            " [ 59.217743  75.08717   96.59888 ]\n",
            " [ 25.902481  44.040894  26.55513 ]\n",
            " [ 11.320435  63.21521  112.00217 ]]\n",
            "[[ 50.260544 140.00002   72.777374]\n",
            " [ 48.910477   5.516136  31.454521]\n",
            " [ 71.96863   78.602936  75.82814 ]\n",
            " [ 44.20018    8.341965   5.951721]\n",
            " [ 15.91938   12.002869  96.00008 ]]\n",
            "[[2.2060127e+01 1.2800018e+02 7.1855286e+01]\n",
            " [7.6147942e+01 1.5966263e+01 3.1785671e+01]\n",
            " [6.4554016e+01 6.8195602e+01 8.4620071e+01]\n",
            " [6.3978226e+01 7.5987305e+01 1.0955811e-02]\n",
            " [1.0401413e+01 7.9859558e+01 1.1600052e+02]]\n",
            "[[ 29.000443  136.00002    82.7278   ]\n",
            " [ 14.512062  107.938705   30.759445 ]\n",
            " [  5.706085  106.326706   39.085358 ]\n",
            " [ 75.774796    3.7138824  47.871788 ]\n",
            " [  4.5690994  12.960342  107.951355 ]]\n",
            "[[ 38.79406  155.99995   34.51642 ]\n",
            " [ 63.545547   8.11264   22.070862]\n",
            " [ 54.977272  60.872086  90.442154]\n",
            " [ 27.686508  67.982086  23.811264]\n",
            " [ 11.573273  87.3452    93.69528 ]]\n",
            "[[ 45.41826   135.99998    83.69748  ]\n",
            " [ 42.039726  115.93446    16.852806 ]\n",
            " [  5.657547  123.393524   78.01572  ]\n",
            " [ 39.92678   119.88603     3.912796 ]\n",
            " [  3.4478455  19.608795  108.000534 ]]\n",
            "[[ 17.944542  135.99997    99.135086 ]\n",
            " [ 46.934402  111.69589    43.79494  ]\n",
            " [ 27.111923   95.60051    75.785126 ]\n",
            " [ 51.25541     1.6735382   8.1579895]\n",
            " [  2.8794556  12.043961  107.99579  ]]\n",
            "[[ 20.870613  135.99995    70.79375  ]\n",
            " [ 32.035492  107.902084   31.989014 ]\n",
            " [ 43.73532    76.37741    79.86807  ]\n",
            " [ 67.78032     7.7400665  47.975533 ]\n",
            " [  4.8468018  17.20739   107.999466 ]]\n",
            "[[ 51.15853   140.00002    18.65754  ]\n",
            " [ 68.029434    7.9972153  20.005096 ]\n",
            " [ 87.90756   143.90254    16.2425   ]\n",
            " [ 16.316055   74.56439     6.315933 ]\n",
            " [ 13.675186   18.032875   81.998505 ]]\n",
            "[[ 36.1082    144.00002   119.268005 ]\n",
            " [ 48.199745   90.60416    18.976791 ]\n",
            " [ 63.431946   84.841446   96.17714  ]\n",
            " [ 25.379776   32.215454    3.1767578]\n",
            " [ 19.735672  119.28293   108.00035  ]]\n",
            "[[ 31.216156 136.00003   88.316345]\n",
            " [ 33.001755  34.80336   20.238304]\n",
            " [ 27.726051 133.73961   27.814217]\n",
            " [  3.999092   4.000244  31.999405]\n",
            " [  5.807724  11.470825 103.99844 ]]\n",
            "[[ 32.069366  143.99994    56.901337 ]\n",
            " [  2.0000153  77.77838     4.4953613]\n",
            " [ 67.996155   73.44183   109.339935 ]\n",
            " [ 56.177456   68.95784     7.603302 ]\n",
            " [ 10.73082    74.62555   107.98155  ]]\n",
            "[[  6.815132  140.         28.49958  ]\n",
            " [ 75.97279    99.887054   15.901375 ]\n",
            " [ 81.285126   75.85812    74.17502  ]\n",
            " [  2.312561   38.811546   60.836754 ]\n",
            " [  1.7664261  57.238007  100.       ]]\n",
            "[[ 27.139885  140.         85.86047  ]\n",
            " [ 51.101944    3.8689194  35.977066 ]\n",
            " [ 32.090973  143.79721    95.9989   ]\n",
            " [ 33.779602   16.821838   13.073288 ]\n",
            " [  3.7037888   2.766693  104.0002   ]]\n",
            "[[ 38.789017  135.99997   103.43878  ]\n",
            " [ 74.30705     2.6528778  25.341011 ]\n",
            " [ 70.12381    91.93848    82.85985  ]\n",
            " [ 77.67004    91.69812    17.964783 ]\n",
            " [  4.099182   69.63867   108.00049  ]]\n",
            "[[ 17.058304  148.00018    92.0591   ]\n",
            " [ 31.667557    2.222374   54.878548 ]\n",
            " [ 11.6356125  70.52121    99.739105 ]\n",
            " [ 19.693344   74.97995     8.124863 ]\n",
            " [ 10.657936   13.47039    53.219864 ]]\n",
            "[[ 19.896912   139.99997     81.841385  ]\n",
            " [ 34.000954    63.57808     21.183334  ]\n",
            " [ 52.06276     64.09326    103.936584  ]\n",
            " [ 10.358231    58.938843    11.906311  ]\n",
            " [  0.71419525   4.1163025   99.95149   ]]\n",
            "[[  1.1800156  135.99998     25.115318  ]\n",
            " [ 74.16913      5.735489     9.8821335 ]\n",
            " [ 67.90051     91.94791     73.32062   ]\n",
            " [ 39.971756     7.3001328   19.21843   ]\n",
            " [  0.13712311  79.07248    107.999695  ]]\n",
            "[[ 20.513657   127.99994     56.75862   ]\n",
            " [ 16.244904     3.992691    26.169502  ]\n",
            " [ 55.919647    59.999695    99.993546  ]\n",
            " [  4.335144    84.52681     10.744797  ]\n",
            " [  0.18281555  64.67145    100.00014   ]]\n",
            "[[ 31.245827  140.00003    24.409897 ]\n",
            " [ 25.13379    54.47673    56.540165 ]\n",
            " [  4.5509033 106.70175    48.849136 ]\n",
            " [ 20.425713   59.52414    15.201233 ]\n",
            " [  1.942627   13.751282  103.967834 ]]\n",
            "[[ 40.394043 140.00002   41.096817]\n",
            " [ 56.856636  12.814575  27.880585]\n",
            " [ 56.        68.000015  88.      ]\n",
            " [  8.114487  57.80069    2.527237]\n",
            " [ 31.662964 123.604355 100.00017 ]]\n",
            "[[  1.148674  115.99991    88.83029  ]\n",
            " [ 55.953537    8.000916   32.000244 ]\n",
            " [ 72.00427    59.990005   95.97485  ]\n",
            " [  4.         12.000015   27.999954 ]\n",
            " [  7.8753204  46.35475   100.00018  ]]\n",
            "[[ 32.54682   131.99997    89.30061  ]\n",
            " [ 49.528755    3.6792603  32.351    ]\n",
            " [ 25.495224   60.59503    99.58644  ]\n",
            " [  3.9598389   8.009026   27.960602 ]\n",
            " [  1.2934265  57.80107   103.97934  ]]\n",
            "[[ 43.823402  144.00005    56.174545 ]\n",
            " [  7.933899  115.99762    43.999664 ]\n",
            " [ 47.508026   86.97873    81.18077  ]\n",
            " [ 51.697235   56.115585    3.9262238]\n",
            " [  1.093956   66.73509   100.000656 ]]\n",
            "[[ 35.885513  143.99997    91.91011  ]\n",
            " [  3.0496368  76.53604    62.14806  ]\n",
            " [ 56.04918    78.37253    87.94705  ]\n",
            " [ 16.00859    68.023254    7.995865 ]\n",
            " [  4.3336334   9.352722  108.00061  ]]\n",
            "[[ 37.089188 159.99997   54.193024]\n",
            " [ 39.999893   7.998825  51.99998 ]\n",
            " [  4.214569 167.71776   16.20272 ]\n",
            " [ 51.999603  15.201683   3.99971 ]\n",
            " [ 13.016846  20.01535   96.000015]]\n",
            "[[ 32.339737  156.00003    15.660217 ]\n",
            " [ 53.942673    7.5773544  21.128365 ]\n",
            " [ 63.99893    68.000275   72.00021  ]\n",
            " [ 13.621536   65.29512     9.528549 ]\n",
            " [ 63.916046  147.81306    55.793144 ]]\n",
            "[[ 29.83593   139.99991    91.398315 ]\n",
            " [ 56.008118    3.6225815  31.991837 ]\n",
            " [ 43.5493    147.58899    33.2686   ]\n",
            " [ 31.996582   71.99751     3.999054 ]\n",
            " [  6.664131   26.806984  103.99861  ]]\n",
            "[[  5.075409  127.9998     41.43618  ]\n",
            " [ 16.071632    4.3624725  55.37921  ]\n",
            " [ 51.98545    59.84514    83.98801  ]\n",
            " [ 19.98832    15.996628   75.991356 ]\n",
            " [  2.7231674  13.097214  104.392456 ]]\n",
            "[[  9.992676  144.         49.02646  ]\n",
            " [ 18.790817    3.3183594  54.467903 ]\n",
            " [  3.162384   85.51285    81.59158  ]\n",
            " [ 50.96959     3.5021439   3.382019 ]\n",
            " [  3.2542496  58.79457   107.99922  ]]\n",
            "[[ 57.11389   151.99994    31.64392  ]\n",
            " [ 69.2481     41.065506   18.977661 ]\n",
            " [ 58.791122   84.01199    79.92804  ]\n",
            " [ 31.922707   75.91373    19.994415 ]\n",
            " [  6.5989685  13.947601  111.99695  ]]\n",
            "[[4.7140930e+01 1.4400003e+02 8.4039856e+01]\n",
            " [7.5757538e+01 6.6917038e+00 1.6096092e+01]\n",
            " [1.6578453e+01 1.5588539e+02 4.9265930e+01]\n",
            " [3.2118744e+01 7.5599854e+01 7.9198608e+00]\n",
            " [1.0865021e-01 1.7172401e+01 1.0399846e+02]]\n",
            "[[ 24.756844  139.99995    83.73192  ]\n",
            " [ 42.29917     2.821846   32.73256  ]\n",
            " [ 56.165543  105.596085   67.009384 ]\n",
            " [ 31.987923   75.99063     8.304611 ]\n",
            " [  3.4396057   3.1305084 108.00046  ]]\n",
            "[[ 14.125626   139.99998     72.72472   ]\n",
            " [ 63.477737     0.47299194  39.90154   ]\n",
            " [ 63.999985    79.98898     84.        ]\n",
            " [ 14.951462    64.96779      9.344345  ]\n",
            " [ 18.843369     5.883789   107.971436  ]]\n",
            "[[5.8423935e+01 1.3599998e+02 4.7236755e+01]\n",
            " [5.1997574e+01 2.4719238e-03 3.6000099e+01]\n",
            " [5.1836914e+01 7.6624054e+01 8.8913544e+01]\n",
            " [2.8002365e+01 7.5994461e+01 3.9984741e+00]\n",
            " [2.2273102e+00 2.2294807e+01 1.0399693e+02]]\n",
            "[[  4.250946  128.00002    71.328    ]\n",
            " [  5.4635773  97.70116    20.419373 ]\n",
            " [  8.471817   82.61415   104.04552  ]\n",
            " [ 15.99987    64.00281    35.999878 ]\n",
            " [  4.4300537  59.737305  104.00035  ]]\n",
            "[[ 13.924896  143.99995    71.73096  ]\n",
            " [ 13.600693    3.9409637  51.48553  ]\n",
            " [ 56.001907   91.95119    71.98547  ]\n",
            " [ 28.008942   67.9998      7.9862976]\n",
            " [  1.8831711  22.196968  107.99776  ]]\n",
            "[[ 38.626183  135.99995    83.96912  ]\n",
            " [ 71.03755     0.7168274  24.114899 ]\n",
            " [ 55.96161    68.00665   103.691864 ]\n",
            " [ 27.058807   75.046524   10.627075 ]\n",
            " [  3.0898743  69.18416    99.99635  ]]\n",
            "[[ 31.677597 159.99998   53.19487 ]\n",
            " [ 54.069397  12.523857  47.84419 ]\n",
            " [ 70.84117  175.99898    6.591942]\n",
            " [ 23.999992  68.         8.000015]\n",
            " [ 13.507721 143.85748  104.00044 ]]\n",
            "[[ 13.708862  135.99994   108.190796 ]\n",
            " [  3.3817291 101.57759    35.34651  ]\n",
            " [ 52.124573   59.84807    99.87494  ]\n",
            " [ 23.980728   96.01895    11.9987335]\n",
            " [  3.0063324  26.099838  108.00061  ]]\n",
            "[[ 32.37622   123.99985    61.57895  ]\n",
            " [ 67.89998     4.978409   32.008514 ]\n",
            " [ 63.990204   74.66853    71.961075 ]\n",
            " [ 18.848099   41.329514    5.8742065]\n",
            " [  2.6689148 103.12727   103.97421  ]]\n",
            "[[ 47.26928    127.99997     69.11662   ]\n",
            " [ 64.46907     11.011345     8.329178  ]\n",
            " [ 59.900146    52.0999      84.19972   ]\n",
            " [ 14.257698    62.86113     19.113327  ]\n",
            " [  0.23539734  96.39572    107.999466  ]]\n",
            "[[ 35.76602  147.99991   68.63823 ]\n",
            " [ 22.867691 123.7728    36.076077]\n",
            " [ 50.114532  61.178726  95.35826 ]\n",
            " [ 23.990952  71.999466  11.99971 ]\n",
            " [  8.18013   80.931564 111.98355 ]]\n",
            "[[  5.0654297 131.99995   116.17633  ]\n",
            " [ 40.001762  104.000015   27.992928 ]\n",
            " [ 48.002243   59.77536    99.99516  ]\n",
            " [  5.7733307  21.322876   21.492737 ]\n",
            " [  5.8244705  37.960693  107.99707  ]]\n",
            "[[ 16.38295  132.00006   57.823914]\n",
            " [ 24.231781  23.48973   12.351051]\n",
            " [ 20.568695  73.27284  107.95232 ]\n",
            " [ 11.999092  67.99748   27.999146]\n",
            " [ 31.198517  47.51158  112.0013  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPkNGPr8hqd9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c2d36b5a-af40-42ea-e24b-0dccefc09bb1"
      },
      "source": [
        "for i in range(164):\n",
        "  pred_example_heatmaps = model_final.predict(x_test1[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_test1[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  print(np.abs(dd-d))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 21.873215  140.00003    92.430786 ]\n",
            " [ 12.361877  100.55911    40.70859  ]\n",
            " [ 57.67282    68.3313     86.011185 ]\n",
            " [ 75.79628     0.389122   51.906685 ]\n",
            " [  1.9129257   8.895813  103.9904   ]]\n",
            "[[ 42.345     155.99997    53.347794 ]\n",
            " [ 75.97514     2.0164871  22.090141 ]\n",
            " [ 17.900085  163.74057    38.290237 ]\n",
            " [ 24.93354    65.70511    25.1474   ]\n",
            " [ 10.981003   47.461884  111.99269  ]]\n",
            "[[ 47.850204  136.00002    67.98276  ]\n",
            " [ 44.142975   38.139465   18.827438 ]\n",
            " [ 39.810684   95.406586   57.90799  ]\n",
            " [ 62.675423    3.5908585  36.16912  ]\n",
            " [  4.0111084   3.4972382 107.997574 ]]\n",
            "[[1.1218948e+01 1.3600000e+02 8.7567215e+00]\n",
            " [4.8812866e-02 1.1833954e-01 9.9978737e+01]\n",
            " [7.6176575e+01 9.0633743e+01 6.8380585e+01]\n",
            " [1.0391296e+01 5.6086426e+00 3.0389221e+01]\n",
            " [1.1998779e+01 6.4014145e+01 1.0400000e+02]]\n",
            "[[ 31.979324 140.        93.7854  ]\n",
            " [ 44.932228 109.13699   37.795326]\n",
            " [ 39.023827 106.87688   56.453278]\n",
            " [ 23.971947  47.954575  15.987045]\n",
            " [ 19.076828  26.563354 100.000015]]\n",
            "[[3.75083313e+01 1.35999939e+02 5.08182678e+01]\n",
            " [1.93439865e+01 3.61602783e+01 3.31692085e+01]\n",
            " [4.36950989e+01 1.43782455e+02 7.05605316e+00]\n",
            " [5.99364166e+01 2.89306641e-02 8.68284607e+00]\n",
            " [3.25554657e+00 1.01032028e+01 1.03999374e+02]]\n",
            "[[ 33.88359  147.99997   14.698746]\n",
            " [ 35.998108 123.9987    51.99996 ]\n",
            " [ 52.19529   91.981964  74.49696 ]\n",
            " [  6.974701  81.512375   9.613983]\n",
            " [ 14.860138  16.923035  87.999985]]\n",
            "[[ 42.37745  139.99997   63.31122 ]\n",
            " [ 23.129913  55.824127  32.357452]\n",
            " [ 48.782257  85.708206  97.643326]\n",
            " [  6.429085  59.014862  29.590485]\n",
            " [ 21.83194   69.90456  104.00003 ]]\n",
            "[[ 22.1044   135.99991   98.492065]\n",
            " [ 75.06729   23.948212  20.121353]\n",
            " [ 28.       144.        92.      ]\n",
            " [ 16.602592  71.635056  17.051788]\n",
            " [ 11.607544  66.477264 100.00044 ]]\n",
            "[[  7.204529  136.00002    36.728714 ]\n",
            " [ 63.99945   112.         12.000046 ]\n",
            " [ 28.        144.         36.       ]\n",
            " [  7.9623184  70.74849    16.74289  ]\n",
            " [ 13.578064    7.788719  107.99138  ]]\n",
            "[[ 18.11728   140.00002    64.32463  ]\n",
            " [ 47.46678   114.96608    39.64148  ]\n",
            " [ 45.86786    92.68411    83.33812  ]\n",
            " [ 47.157074    9.175606   13.309937 ]\n",
            " [  1.9198227  12.975426  107.99049  ]]\n",
            "[[3.0542007e+01 1.3999995e+02 8.7898972e+01]\n",
            " [5.8263565e+01 5.5267334e-02 3.6319511e+01]\n",
            " [7.1927719e+01 2.0239349e+01 5.6100861e+01]\n",
            " [5.5844055e+01 7.9028931e+00 7.8431549e+00]\n",
            " [1.2722931e+00 6.0298538e+00 1.0306390e+02]]\n",
            "[[ 28.040474   143.99998     96.788315  ]\n",
            " [ 51.9635       1.2723083   36.656708  ]\n",
            " [ 56.004684    76.00081     83.98564   ]\n",
            " [ 47.341827    14.990356     3.186905  ]\n",
            " [  3.7274246    0.30786133 107.92207   ]]\n",
            "[[ 30.84407  156.00003   71.253815]\n",
            " [ 36.549187   8.877441  36.206696]\n",
            " [ 63.999985  59.99997   95.99992 ]\n",
            " [ 19.971535  75.99069   20.002533]\n",
            " [ 54.162476 141.51974   37.233215]]\n",
            "[[  8.068497  136.        103.231476 ]\n",
            " [ 51.844284    3.727539   52.027096 ]\n",
            " [ 66.95334    79.617935   58.306046 ]\n",
            " [  6.9859695  75.30434    20.561584 ]\n",
            " [  5.0551147  17.973328  100.00009  ]]\n",
            "[[ 24.064255  132.00002    96.559525 ]\n",
            " [ 67.99992     4.0157623  16.000221 ]\n",
            " [ 11.195404   71.600266   85.38658  ]\n",
            " [  6.463379   49.94449     3.2908936]\n",
            " [  1.186554    9.388496  107.99727  ]]\n",
            "[[2.8722420e+01 1.3200000e+02 8.6152557e+01]\n",
            " [1.1572418e+00 1.0413873e+02 3.3259445e+01]\n",
            " [4.9585342e+01 6.3225708e+01 1.0580455e+02]\n",
            " [3.1983719e+01 6.3999695e+01 1.1994583e+01]\n",
            " [9.3894958e-02 1.4873352e+01 1.0399631e+02]]\n",
            "[[ 27.873795  131.99997    88.03662  ]\n",
            " [ 56.281937   95.16786    28.410347 ]\n",
            " [ 17.764603  116.99518    40.558395 ]\n",
            " [  0.4416809  22.042679   45.01577  ]\n",
            " [ 10.879944   83.76169   104.00119  ]]\n",
            "[[ 36.5952    168.00002    66.68382  ]\n",
            " [ 75.21466     3.9725418   9.075592 ]\n",
            " [ 79.99321    76.336      59.653748 ]\n",
            " [ 23.343307    4.366646   32.246338 ]\n",
            " [  8.403305   59.36061   111.994995 ]]\n",
            "[[ 37.43161   136.00002    93.28096  ]\n",
            " [ 13.194855    1.3582611  36.22467  ]\n",
            " [ 63.939667   77.430145   99.751724 ]\n",
            " [ 62.83618    15.814598    4.068451 ]\n",
            " [  8.373978   60.457214  104.00043  ]]\n",
            "[[ 19.684975  136.         69.669586 ]\n",
            " [ 61.440353    2.3361435  45.347736 ]\n",
            " [  4.393791  138.72551     8.440292 ]\n",
            " [ 63.796616   12.703842    4.8111877]\n",
            " [  0.8393936  61.341125  104.00017  ]]\n",
            "[[ 25.924332  128.00002    77.757904 ]\n",
            " [ 71.18036     1.8660583  24.212929 ]\n",
            " [ 54.244896   57.00885    91.92934  ]\n",
            " [ 23.967346   76.00656    23.999222 ]\n",
            " [ 11.849106   59.963806   99.999985 ]]\n",
            "[[ 20.301361  131.99994   100.40251  ]\n",
            " [  5.7876053   1.7756653  89.267166 ]\n",
            " [ 46.83458   119.95795    43.177933 ]\n",
            " [ 32.         99.99991    16.000015 ]\n",
            " [  3.9922562  76.00038   104.000046 ]]\n",
            "[[ 23.207062 144.00002   85.19394 ]\n",
            " [ 33.447205  74.94559   29.223526]\n",
            " [ 59.21762   74.30415   86.435394]\n",
            " [ 15.028458  22.752747  23.193924]\n",
            " [  7.331848  79.13721  107.997375]]\n",
            "[[ 28.050735  139.99997   102.73015  ]\n",
            " [ 11.271484  111.28798    75.52582  ]\n",
            " [ 71.74547    48.811188   64.22328  ]\n",
            " [ 27.884811   80.82301    16.       ]\n",
            " [  1.1935501  26.056473  112.000916 ]]\n",
            "[[  1.0451126 128.         39.517426 ]\n",
            " [ 38.41935     1.7114029  37.16265  ]\n",
            " [ 54.579773   86.9256     85.80083  ]\n",
            " [ 19.309708   83.380646    8.247345 ]\n",
            " [ 28.058617   23.08345    92.00011  ]]\n",
            "[[  5.6067657 135.99994    71.50603  ]\n",
            " [ 12.212631   10.829056   64.747955 ]\n",
            " [ 74.89589    45.330917   43.321365 ]\n",
            " [ 31.487503   80.27963    11.966736 ]\n",
            " [  1.861229   59.311295   99.99936  ]]\n",
            "[[  9.320351   131.99991     57.60588   ]\n",
            " [ 59.999893   111.99991     39.993446  ]\n",
            " [  4.000847    80.00574     23.999733  ]\n",
            " [ 28.11435     73.59807     10.691406  ]\n",
            " [  0.17881775  28.110199   100.001205  ]]\n",
            "[[ 14.710358  131.99995    34.170364 ]\n",
            " [ 54.749443    1.8130264  40.524353 ]\n",
            " [ 47.14984    96.7601     61.7258   ]\n",
            " [ 32.01114    83.97339    11.990219 ]\n",
            " [  2.4620361  60.93602    99.9998   ]]\n",
            "[[ 12.302322  128.00003    82.49276  ]\n",
            " [ 63.755417    3.9836273  27.990456 ]\n",
            " [ 33.519753   64.05252    96.051605 ]\n",
            " [ 39.99106    72.000565   15.971527 ]\n",
            " [  1.345314    1.4982605 103.95836  ]]\n",
            "[[4.2535843e+01 1.3199998e+02 4.9780762e+01]\n",
            " [9.2887878e-02 1.0829816e+02 5.1878799e+01]\n",
            " [5.5989311e+01 1.3599268e+02 2.0014473e+01]\n",
            " [8.0000610e+00 4.0000687e+00 2.7999908e+01]\n",
            " [4.1855164e+00 3.6301147e+01 9.1483124e+01]]\n",
            "[[ 29.019562  139.99992    23.066322 ]\n",
            " [  7.129013   87.44011    44.793694 ]\n",
            " [ 46.727203  132.73232    52.636154 ]\n",
            " [ 23.988434   78.285095   15.90834  ]\n",
            " [  1.7955322  76.38939   108.002    ]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-0a17c83025d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m164\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mpred_example_heatmaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_example_heatmaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdd\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mspatial_softArgmax3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m4.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 32 is out of bounds for axis 0 with size 32"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00VhSnPcQ1dz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "s_train1 = 0\n",
        "for i in range(164):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  s_train1 = s_train1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  #for j in range(5):\n",
        "   # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "\n",
        "\n",
        "s_train2 = 0\n",
        "for i in range(164):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  \n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "  #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "  #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "  s_train2 = s_train2 + np.mean((np.abs(d-dd)))\n",
        "  #for j in range(5):\n",
        "   # s_train2 = s_train2 + ((d[j,0]-dd[j,0])+np.abs(d[j,1]-dd[j,1])+np.abs(d[j,2]-dd[j,2]))\n",
        "\n",
        "\n",
        "\n",
        "points = []\n",
        "count = 0\n",
        "for i in range(164):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  points.append(d)\n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "print(\"Train MEE : {}\".format(s_train1/(164)))\n",
        "print(\"Train MAE : {}\".format(s_train2/(164)))\n",
        "print((count/(5*164))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gfYleNzQ5Pl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "s_val1 = 0\n",
        "for i in range(164,206):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  s_val1 = s_val1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  #for j in range(5):\n",
        "   # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "\n",
        "\n",
        "s_val2 = 0\n",
        "for i in range(164,206):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  \n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "  #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "  #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "  s_val2 = s_val2 + np.mean((np.abs(d-dd)))\n",
        "  #for j in range(5):\n",
        "   # s_train2 = s_train2 + ((d[j,0]-dd[j,0])+np.abs(d[j,1]-dd[j,1])+np.abs(d[j,2]-dd[j,2]))\n",
        "\n",
        "\n",
        "\n",
        "points = []\n",
        "count = 0\n",
        "for i in range(164,206):\n",
        "  pred_example_heatmaps = model_final.predict(x_data[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_data[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  points.append(d)\n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "print(\"Train MEE : {}\".format(s_train1/(42)))\n",
        "print(\"Train MAE : {}\".format(s_train2/(42)))\n",
        "print((count/(5*42))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HkJzNIuQ9wP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math \n",
        "\n",
        "s_test1 = 0\n",
        "for i in range(32):\n",
        "  pred_example_heatmaps = model_final.predict(x_test[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_test[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  s_test1 = s_test1 + np.mean(np.sqrt(np.sum(np.square(d-dd),axis=1)))\n",
        "  #for j in range(5):\n",
        "   # s_train1 = s_train1 + math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)\n",
        "\n",
        "\n",
        "s_test2 = 0\n",
        "for i in range(32):\n",
        "  pred_example_heatmaps = model_final.predict(x_test[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  \n",
        "  m = y_test[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "\n",
        "  #d = d = landmarks(y_train[i,:,:,:,:])\n",
        "  #print (np.sum((np.abs(a-b)))/5)\n",
        "\n",
        "  s_test2 = s_test2 + np.mean((np.abs(d-dd)))\n",
        "  #for j in range(5):\n",
        "   # s_train2 = s_train2 + ((d[j,0]-dd[j,0])+np.abs(d[j,1]-dd[j,1])+np.abs(d[j,2]-dd[j,2]))\n",
        "\n",
        "\n",
        "\n",
        "points = []\n",
        "count = 0\n",
        "for i in range(32):\n",
        "  pred_example_heatmaps = model_final.predict(x_test[i,:,:,:,:])\n",
        "  a = tf.convert_to_tensor(pred_example_heatmaps, np.float32)\n",
        "  a = tf.transpose(a, [3, 0, 1, 2 ,4])\n",
        "  dd =  spatial_softArgmax3d(a)*4.0\n",
        "  p = dd.numpy()\n",
        "  m = y_test[i,:,:,:,:]\n",
        "  m = m.reshape(1,64,64,64,5)\n",
        "  b = tf.convert_to_tensor(m, np.float32)\n",
        "  d =  spatial_softArgmax3d(b)*4.0\n",
        "  points.append(d)\n",
        "  for j in range(5):\n",
        "    if math.sqrt((d[j,0]-dd[j,0])**2+(d[j,1]-dd[j,1])**2+(d[j,2]-dd[j,2])**2)<7:\n",
        "      count = count+1\n",
        "\n",
        "print(\"Train MEE : {}\".format(s_train1/(32)))\n",
        "print(\"Train MAE : {}\".format(s_train2/(32)))\n",
        "print((count/(5*32))*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbeIR1zcPIEF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "8984433c-3174-49cd-e899-84efe6aa8077"
      },
      "source": [
        "%matplotlib inline\n",
        "hist = History\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "t = f.suptitle('Model Performance graphs', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "epoch_list = hist.epoch\n",
        "\n",
        "ax1.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
        "ax1.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax1.set_ylabel('loss Value');ax1.set_xlabel('Epoch');ax1.set_title('Loss')\n",
        "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax2.plot(epoch_list, hist.history['MEE'], label='Train MEE')\n",
        "ax2.plot(epoch_list, hist.history['val_MEE'], label='Validation MEE')\n",
        "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax2.set_ylabel('euclidean_distance_loss');ax2.set_xlabel('Epoch');ax2.set_title('Mean Euclidean Loss')\n",
        "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax3.plot(epoch_list, hist.history['MAE'], label='Train Mean Absolute Error')\n",
        "ax3.plot(epoch_list, hist.history['val_MAE'], label='Validation Mean Absolute Error')\n",
        "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax3.set_ylabel('Mean Absolute Error');ax3.set_xlabel('Epoch');ax3.set_title('Mean Absolute Error')\n",
        "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8PrqkrdPJJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "hist = His[1]\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "t = f.suptitle('Model Performance graphs', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "epoch_list = hist.epoch\n",
        "\n",
        "ax1.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
        "ax1.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax1.set_ylabel('loss Value');ax1.set_xlabel('Epoch');ax1.set_title('Loss')\n",
        "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax2.plot(epoch_list, hist.history['MEE'], label='Train MEE')\n",
        "ax2.plot(epoch_list, hist.history['val_MEE'], label='Validation MEE')\n",
        "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax2.set_ylabel('euclidean_distance_loss');ax2.set_xlabel('Epoch');ax2.set_title('Mean Euclidean Loss')\n",
        "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax3.plot(epoch_list, hist.history['MAE'], label='Train Mean Absolute Error')\n",
        "ax3.plot(epoch_list, hist.history['val_MAE'], label='Validation Mean Absolute Error')\n",
        "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax3.set_ylabel('Mean Absolute Error');ax3.set_xlabel('Epoch');ax3.set_title('Mean Absolute Error')\n",
        "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FG1QGmqPPLG3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "hist = His[2]\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "t = f.suptitle('Model Performance graphs', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "epoch_list = hist.epoch\n",
        "\n",
        "ax1.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
        "ax1.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax1.set_ylabel('loss Value');ax1.set_xlabel('Epoch');ax1.set_title('Loss')\n",
        "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax2.plot(epoch_list, hist.history['MEE'], label='Train MEE')\n",
        "ax2.plot(epoch_list, hist.history['val_MEE'], label='Validation MEE')\n",
        "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax2.set_ylabel('euclidean_distance_loss');ax2.set_xlabel('Epoch');ax2.set_title('Mean Euclidean Loss')\n",
        "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax3.plot(epoch_list, hist.history['MAE'], label='Train Mean Absolute Error')\n",
        "ax3.plot(epoch_list, hist.history['val_MAE'], label='Validation Mean Absolute Error')\n",
        "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax3.set_ylabel('Mean Absolute Error');ax3.set_xlabel('Epoch');ax3.set_title('Mean Absolute Error')\n",
        "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNcyW8uLPMzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "hist = His[3]\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "t = f.suptitle('Model Performance graphs', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "epoch_list = hist.epoch\n",
        "\n",
        "ax1.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
        "ax1.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax1.set_ylabel('loss Value');ax1.set_xlabel('Epoch');ax1.set_title('Loss')\n",
        "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax2.plot(epoch_list, hist.history['MEE'], label='Train MEE')\n",
        "ax2.plot(epoch_list, hist.history['val_MEE'], label='Validation MEE')\n",
        "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax2.set_ylabel('euclidean_distance_loss');ax2.set_xlabel('Epoch');ax2.set_title('Mean Euclidean Loss')\n",
        "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax3.plot(epoch_list, hist.history['MAE'], label='Train Mean Absolute Error')\n",
        "ax3.plot(epoch_list, hist.history['val_MAE'], label='Validation Mean Absolute Error')\n",
        "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax3.set_ylabel('Mean Absolute Error');ax3.set_xlabel('Epoch');ax3.set_title('Mean Absolute Error')\n",
        "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WsbI03GPOhy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "hist = His[4]\n",
        "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(16, 4))\n",
        "t = f.suptitle('Model Performance graphs', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "epoch_list = hist.epoch\n",
        "\n",
        "ax1.plot(epoch_list, hist.history['loss'], label='Train Loss')\n",
        "ax1.plot(epoch_list, hist.history['val_loss'], label='Validation Loss')\n",
        "ax1.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax1.set_ylabel('loss Value');ax1.set_xlabel('Epoch');ax1.set_title('Loss')\n",
        "ax1.legend(loc=\"best\");ax1.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax2.plot(epoch_list, hist.history['MEE'], label='Train MEE')\n",
        "ax2.plot(epoch_list, hist.history['val_MEE'], label='Validation MEE')\n",
        "ax2.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax2.set_ylabel('euclidean_distance_loss');ax2.set_xlabel('Epoch');ax2.set_title('Mean Euclidean Loss')\n",
        "ax2.legend(loc=\"best\");ax2.grid(color='gray', linestyle='-', linewidth=0.5)\n",
        "\n",
        "ax3.plot(epoch_list, hist.history['MAE'], label='Train Mean Absolute Error')\n",
        "ax3.plot(epoch_list, hist.history['val_MAE'], label='Validation Mean Absolute Error')\n",
        "ax3.set_xticks(np.arange(0, epoch_list[-1], 5))\n",
        "ax3.set_ylabel('Mean Absolute Error');ax3.set_xlabel('Epoch');ax3.set_title('Mean Absolute Error')\n",
        "ax3.legend(loc=\"best\");ax3.grid(color='gray', linestyle='-', linewidth=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhtsT4PRPQLC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import save\n",
        "\n",
        "save('/content/drive/My Drive/Database/Model_training_5/DA1/metrics.npy',np.array([metric_train,metric_val,metric_test]))\n",
        "\n",
        "\n",
        "model_final.save('/content/drive/My Drive/Database/Model_training_5/DA1/Flat_net.h5')  \n",
        "model_final = tf.keras.models.load_model('/content/drive/My Drive/Database/Model_training_3/DA2/Flat_net.h5', custom_objects={'custom_loss_reg_1': custom_loss_reg_1,'MAE': MAE,'MEE':MEE})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}